{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJ6yBvhknLcLom04ZieDef",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PouriaRouzrokh/AI-Deep-Learning-Lab-2025/blob/main/DL%20Lab%20-%20An%20Introduction%20to%20Multi-agent%20Artificial%20Intelligence%20Systems%20in%20Radiology/RSNA2025_DLL_AgentiAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**An Introduction to Multi-agent Artificial Intelligence Systems in Radiology**\n",
        "\n",
        "\n",
        "- **Moderator:** Pouria Rouzrokh MD MPH MHPE [[1]](https://www.linkedin.com/in/pouria-rouzrokh/)\n",
        "- **Speaker:** Moein Shariatnia MD [[2]](https://www.linkedin.com/in/melina-hosseiny-m-d-0a12b7a1)  \n",
        "- **Speaker:** Melina Hosseiny MD [[3]](https://www.linkedin.com/in/moein-shariatnia?originalSubdomain=ir)\n",
        "\n",
        "## Overview\n",
        "\n",
        "Welcome to the Deep Learning Labs at RSNA2025!\n",
        "\n",
        "In this hands-on workshop, we will explore the concept of AI agents, emphasizing their importance and unique advantages over single, monolithic language models.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "This notebook provides a quick introduction to building agentic and multi-agent AI systems using **Google's Agent Development Kit (ADK)**. Using this framework, we'll explore:\n",
        "\n",
        "1. **Basic Agents**: Simple LLM-based agents without tools\n",
        "2. **Augmented Agents**: Agents enhanced with tools (e.g., Google Search)\n",
        "3. **Multi-Agent Pipelines**: Sequential, parallel, and loop architectures\n",
        "4. **Advanced Tools and Pipelines**: How to equip our agents to MCP tools, run them independantly, and many more things!\n",
        "\n",
        "And at the very end of this notebook, we will also look at a more production-ready product built with the Google ADK framework so that you can see the actual power of AI agents; ***so stay tuned!***\n",
        "\n",
        "---\n",
        "*P.S. Throughout this notebook, the term ‚Äúagent‚Äù is used broadly to describe many types of chatbots, including those that are essentially LLMs or augmented LLMs rather than true agents. This aligns with the general usage of the term ‚Äúagent‚Äù within the Google ADK.*"
      ],
      "metadata": {
        "id": "6ckRGIStQMrv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by downloading the data that we need and setting up the scene!"
      ],
      "metadata": {
        "id": "Nx8xyP66O_Hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "from urllib.parse import unquote\n",
        "\n",
        "def clone_specific_folder(repo_and_path, destination=None):\n",
        "    repo_and_path = unquote(repo_and_path)\n",
        "\n",
        "    parts = repo_and_path.split(\"/tree/\")\n",
        "    base = parts[0].replace(\"https://github.com/\", \"\")\n",
        "    repo_url = f\"https://github.com/{base}.git\"\n",
        "    branch_and_path = parts[1].split(\"/\", 1)\n",
        "    branch = branch_and_path[0]\n",
        "    folder_path = branch_and_path[1] if len(branch_and_path) > 1 else \"\"\n",
        "\n",
        "    folder_path = folder_path.rstrip(\"/\")\n",
        "    destination = destination or os.path.basename(folder_path) or \"cloned_repo\"\n",
        "\n",
        "    os.makedirs(destination, exist_ok=True)\n",
        "    cwd = os.getcwd()\n",
        "    os.chdir(destination)\n",
        "\n",
        "    subprocess.run([\"git\", \"init\"], capture_output=True)\n",
        "    subprocess.run([\"git\", \"remote\", \"add\", \"origin\", repo_url], capture_output=True)\n",
        "    subprocess.run([\"git\", \"config\", \"core.sparseCheckout\", \"true\"], capture_output=True)\n",
        "\n",
        "    with open(\".git/info/sparse-checkout\", \"w\") as f:\n",
        "        f.write(f\"{folder_path}/*\\n\" if folder_path else \"*\\n\")\n",
        "\n",
        "    try:\n",
        "        subprocess.run([\"git\", \"pull\", \"origin\", branch], check=True, capture_output=True)\n",
        "    except:\n",
        "        subprocess.run([\"git\", \"pull\", \"origin\", \"master\"], check=True, capture_output=True)\n",
        "\n",
        "    if folder_path and os.path.exists(folder_path):\n",
        "        shutil.move(folder_path, \"_temp\")\n",
        "        for item in os.listdir(\".\"):\n",
        "            if item not in [\"_temp\", \".git\"]:\n",
        "                shutil.rmtree(item) if os.path.isdir(item) else os.remove(item)\n",
        "        for item in os.listdir(\"_temp\"):\n",
        "            shutil.move(f\"_temp/{item}\", \".\")\n",
        "        shutil.rmtree(\"_temp\")\n",
        "\n",
        "    os.chdir(cwd)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yVQudwF3NfKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtsCJWuVLUg5"
      },
      "outputs": [],
      "source": [
        "# Ignore the warnings (Google ADK has lots of warnings!)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Clone the deep learning lab data from the RSNA2025 Deep Learning Labs repository.\n",
        "target_link = \"https://github.com/RSNA/AI-Deep-Learning-Lab-2025/tree/main/DL%20Lab%20-%20An%20Introduction%20to%20Multi-agent%20Artificial%20Intelligence%20Systems%20in%20Radiology/scripts/agents\"\n",
        "clone_specific_folder(target_link)\n",
        "\n",
        "# Remove the sample_data folder\n",
        "shutil.rmtree(\"sample_data\", ignore_errors=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Your Google API Key\n",
        "\n",
        "The Google ADK framework works with the Gemini family of large language models by default (it can also work with other models like OpenAI, Claude, etc.). To run this notebook smoothly, you'll need an API key from Google. Google provides everyone with a free API key that includes a generous free tier, and even if you exceed the free tier, the costs for these language models are negligible.\n",
        "\n",
        "To get your API key, open the following link (if you're attending the workshop in person, follow along on the screen):\n",
        "\n",
        "[https://aistudio.google.com/app/api-keys](https://aistudio.google.com/app/api-keys)\n",
        "\n",
        "After you get your API key, go ahead and enter it in the cell below, which will securely store it for use in this notebook."
      ],
      "metadata": {
        "id": "d0Im04z4SS2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Securely prompt for API key\n",
        "api_key = getpass('Enter your Google API Key: ')\n",
        "\n",
        "# Set the API key as an environment variable\n",
        "os.environ['GOOGLE_API_KEY'] = api_key\n",
        "\n",
        "print(\"‚úì API key has been set successfully!\")"
      ],
      "metadata": {
        "id": "-kTQ-_OkTBli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab961c3f-e3f3-4254-92ca-f690875b96d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Google API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úì API key has been set successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last but not least, we need to install the packages that we need for our today's workshop."
      ],
      "metadata": {
        "id": "XEeKy9ANUvSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q google-adk python-dotenv requests pydantic"
      ],
      "metadata": {
        "id": "x95cH7WIUu_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, now we are ready to start talking about agents!"
      ],
      "metadata": {
        "id": "HvN6r82JT99R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1. An Introduction to AI Agents**\n",
        "\n",
        "> Associated Agent: **basic_radiology_assistant**\n",
        "\n",
        "At its core, an **agent** is a Large Language Model (LLM) enhanced with the ability to perform tasks and make decisions in a semi-automated way. Unlike a plain LLM that only answers a single query, an agent can:\n",
        "\n",
        "- Receive user input\n",
        "- Process it using both its pre-trained knowledge and, if available, predefined external tools\n",
        "- Make decisions step-by-step, continuing its work toward a goal, reaching checkpoints, or halting if guardrails or stopping criteria are triggered\n",
        "- Return an answer or outcome‚Äînot just in response to a question, but potentially after a sequence of actions or automated reasoning steps\n",
        "\n",
        "A basic agent without any tools behaves just like an LLM (using only its internal knowledge), but more advanced agents can reason, use external tools, and act with degrees of autonomy.\n"
      ],
      "metadata": {
        "id": "CHFi6o8AUDLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1\\. Writing your first agent with Google ADK**\n",
        "\n",
        "To begin exploring the world of agents, let‚Äôs first build a dummy radiology assistant agent that can answer any questions you have about radiology. Despite this mouthful of a title, this ‚Äúagent‚Äù is, in fact, just a large language model (such as Gemini 2.5 Flash in our case) that we instruct to only answer radiology-related questions. It will not have any tools and will not be able to do anything fancy apart from continuing the conversation as much as needed, which is basically something every large language model can do. They are all quite verbose, after all :)\n",
        "\n",
        "Take a look at the code below to see how we can implement this using the Google ADK.\n",
        "\n",
        "```python\n",
        "from google.adk.agents import Agent\n",
        "\n",
        "# Define the basic radiology assistant agent\n",
        "basic_radiology_assistant = Agent(\n",
        "    name=\"basic_radiology_assistant\",\n",
        "    model=\"gemini-2.5-flash\",  # Using Gemini Flash model\n",
        "    instruction=(\n",
        "        \"You are a helpful assistant specialized in radiology. \"\n",
        "        \"Your primary role is to answer questions about radiology, including:\\n\"\n",
        "        \"- Medical imaging techniques and modalities\\n\"\n",
        "        \"- Radiological findings and interpretations\\n\"\n",
        "        \"- Anatomy and pathology relevant to radiology\\n\"\n",
        "        \"- Imaging protocols and best practices\\n\"\n",
        "        \"- Radiological terminology and concepts\\n\\n\"\n",
        "        \"You should politely decline to answer questions that are not related to radiology. \"\n",
        "        \"When asked about non-radiology topics, kindly redirect the conversation back to \"\n",
        "        \"radiology-related questions.\"\n",
        "    ),\n",
        "    description=(\n",
        "        \"A basic specialized assistant that answers questions about radiology and \"\n",
        "        \"avoids answering miscellaneous questions. No web search capabilities.\"\n",
        "    ),\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "CSzBhNW5Xiap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the agent receives a few arguments, the most important of which is its instructions. In addition to instructions, you might notice that the agent also takes a description, a name, and, obviously, a model. The model is essentially the ‚Äúbrain‚Äù of the agent, and we can pass any of the Gemini models to Google ADK agents. However, it is important to note that we can also pass other families of models, such as those from OpenAI and Anthropic, to Google ADK as well. This is very straightforward, and you can read more about it in the documentation, but we will not delve into those details in this notebook.\n",
        "\n",
        "You may wonder why this agent needs both a name and a description. After all, the instructions alone would suffice for this simple, single-agent task. As we move forward and our agent systems become more complex, however, each agent will increasingly need an identity. Agents need to understand each other‚Äôs ‚Äúphilosophy of being,‚Äù main responsibilities, and reason for existing. The name and description of an agent are primarily used so that other agents can refer to it and understand its role. Since we only have a single agent here, this will become more important later when we introduce multi-agent setups."
      ],
      "metadata": {
        "id": "X8Mbm7FDmGzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**2\\. Executing your first agent**\n",
        "\n",
        "Well, now that we have coded our very first simple agent, you might be waiting for us to show you the syntax for executing this agent from this current notebook. However, when it comes to **Google ADK**, you should bear in mind that this package has been built with ultimate prioritization of deployment.\n",
        "\n",
        "But being deployment-ready does not necessarily mean that it is user-friendly‚Äîor at least notebook-friendly in our case. In fact, running Google ADK agents is most of the time easier from within the **terminal** when they are defined inside Python scripts rather than from within a Jupyter or Google Colab environment.\n",
        "\n",
        "Of course, there are ways for running the agents in notebook environments, but those might be a little more complicated for beginners and we will not get into those approaches until the very last agent that we will deploy together.\n",
        "\n",
        "---\n",
        "\n",
        "So what other ways do we have for running them, you might ask? Well, easy! Thankfully, we can still run CLI commands from Google Colab through by adding a \"!\" to the start of a code cell line. This will tell Colab that the commands need to be interpreted from shell. Now that we know this trick, we can use all our agents by running a command like the following: `adk run agents/basic_radiology_assistant`.\n",
        "\n",
        "This will open a very basic chat interface with the agent in terminal, which will still work but might not be that beautiful. The following cell will implement a function to Display our conversation with the agents in a more decent way. Obviously, this function is entirely optional and its content is not relevant to our workshop at all, so feel free to ignore it if you don't feel like reading it."
      ],
      "metadata": {
        "id": "DXTHGIjYjHTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Optional code to format the appearance of chat conversation with agents.\n",
        "\n",
        "# 1. Ensure markdown library is present\n",
        "import sys\n",
        "import subprocess\n",
        "try:\n",
        "    import markdown\n",
        "except ImportError:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"markdown\"])\n",
        "    import markdown\n",
        "\n",
        "import pexpect\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from IPython.display import display, HTML, clear_output\n",
        "\n",
        "def chat_with_agent_clean(agent_path, session_id=None):\n",
        "    # --- CONFIGURATION ---\n",
        "    TITLES = {\n",
        "        \"part1\": \"Part 1: Basic Radiology Assistant\",\n",
        "        \"part2\": \"Part 2: Web Search Assistant\",\n",
        "        \"part3\": \"Part 3: Biography Agent\",\n",
        "        \"part4\": \"Part 4: Biography Agent (Fixed)\",\n",
        "        \"part5\": \"Part 5: Networking Agent\",\n",
        "        \"part6\": \"Part 6: Radiology Researcher Agent\"\n",
        "    }\n",
        "\n",
        "    match = re.search(r'(part\\d+)', agent_path, re.IGNORECASE)\n",
        "    display_title = TITLES.get(match.group(1).lower()) if match and match.group(1).lower() in TITLES else os.path.basename(agent_path).replace('_', ' ').title()\n",
        "\n",
        "    session_html = f'<span style=\"color: #d9534f; font-weight: bold; margin-left: 10px;\">üî¥ Recording Session: {session_id}</span>' if session_id else '<span style=\"color: #888;\">Interactive ADK Session</span>'\n",
        "\n",
        "    chat_history = []\n",
        "\n",
        "    # --- RENDER ENGINE ---\n",
        "    def render_chat(history, status=None):\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        css = '''\n",
        "        <style>\n",
        "            .chat-container { max-width: 700px; margin: 0 auto; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }\n",
        "            .agent-row { display: flex; margin-bottom: 20px; align-items: flex-start; }\n",
        "            .user-row { display: flex; margin-bottom: 20px; justify-content: flex-end; align-items: flex-end; }\n",
        "            .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }\n",
        "            .avatar-agent { background: #f0f0f0; margin-right: 15px; margin-top: 5px; }\n",
        "            .avatar-user { background: #e3f2fd; margin-left: 15px; }\n",
        "            .agent-bubble { background-color: #f8f9fa; color: #1a1a1a; padding: 15px 22px; border-radius: 20px; border-top-left-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }\n",
        "            .user-bubble { background-color: #007bff; color: white; padding: 15px 22px; border-radius: 20px; border-bottom-right-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; text-align: left; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }\n",
        "\n",
        "            /* Markdown Styles */\n",
        "            .agent-bubble p { margin: 0 0 10px 0; } .agent-bubble p:last-child { margin: 0; }\n",
        "            .agent-bubble ul, .agent-bubble ol { margin: 5px 0 10px 20px; padding: 0; }\n",
        "            .agent-bubble li { margin-bottom: 5px; }\n",
        "            .agent-bubble strong { font-weight: 700; color: #000; }\n",
        "            .agent-bubble pre { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 8px; overflow-x: auto; }\n",
        "            .agent-bubble code { background: #eee; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }\n",
        "            .agent-bubble pre code { background: transparent; padding: 0; color: #f8f8f2; }\n",
        "\n",
        "            .status-indicator { font-size: 13px; color: #888; text-align: center; margin-top: 20px; font-style: italic; animation: pulse 1.5s infinite; }\n",
        "            @keyframes pulse { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }\n",
        "            .sys-log { font-family: monospace; font-size: 11px; color: #aaa; margin: 5px 0; text-align: center; }\n",
        "        </style>\n",
        "        '''\n",
        "\n",
        "        html = f'''{css}\n",
        "        <div class=\"chat-container\">\n",
        "            <h2 style=\"color: #333; margin-bottom: 5px; text-align: center;\">ü©∫ {display_title}</h2>\n",
        "            <p style=\"font-size: 13px; margin-top: 0; text-align: center;\">{session_html}</p>\n",
        "            <hr style=\"border: 0; border-top: 1px solid #eee; margin-bottom: 30px;\">\n",
        "        '''\n",
        "\n",
        "        for msg in history:\n",
        "            if msg['role'] == 'sys':\n",
        "                html += f'<div class=\"sys-log\">{msg[\"content\"]}</div>'\n",
        "            elif msg['role'] == 'agent':\n",
        "                # MODIFIED: Added extensions=['nl2br', 'fenced_code']\n",
        "                # nl2br: Converts newlines to <br> tags\n",
        "                # fenced_code: Allows proper rendering of ```code blocks```\n",
        "                formatted_text = markdown.markdown(msg['content'], extensions=['nl2br', 'fenced_code'])\n",
        "                html += f'<div class=\"agent-row\"><div class=\"avatar avatar-agent\">ü§ñ</div><div class=\"agent-bubble\">{formatted_text}</div></div>'\n",
        "            elif msg['role'] == 'user':\n",
        "                html += f'<div class=\"user-row\"><div class=\"user-bubble\">{msg[\"content\"]}</div><div class=\"avatar avatar-user\">üë§</div></div>'\n",
        "\n",
        "        if status:\n",
        "            html += f'<div class=\"status-indicator\">{status}</div>'\n",
        "\n",
        "        html += '</div>'\n",
        "        display(HTML(html))\n",
        "\n",
        "    # --- START PROCESS ---\n",
        "    cmd = f\"adk run {agent_path}\"\n",
        "    if session_id:\n",
        "        cmd += f\" --save_session --session_id {session_id}\"\n",
        "\n",
        "    env = os.environ.copy()\n",
        "    env[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "    child = pexpect.spawn(cmd, env=env, encoding='utf-8', timeout=None)\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    try: child.setecho(False)\n",
        "    except: pass\n",
        "\n",
        "    last_user_input = \"\"\n",
        "\n",
        "    render_chat(chat_history, status=\"üü¢ Starting Agent...\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            index = child.expect(['\\[user\\]:', pexpect.EOF])\n",
        "\n",
        "            if index == 0: # Prompt found\n",
        "                raw = child.before.strip()\n",
        "\n",
        "                if last_user_input and raw.startswith(last_user_input):\n",
        "                    raw = raw[len(last_user_input):].strip()\n",
        "\n",
        "                agent_lines = []\n",
        "                for line in raw.split('\\n'):\n",
        "                    line = line.strip()\n",
        "                    if not line: continue\n",
        "                    if any(x in line for x in [\"Log setup\", \"Running agent\", \"To access latest\", \"Type exit\"]):\n",
        "                        chat_history.append({'role': 'sys', 'content': line})\n",
        "                    else:\n",
        "                        clean = re.sub(r'^\\[.*?\\]:\\s*', '', line)\n",
        "                        if clean: agent_lines.append(clean)\n",
        "\n",
        "                if agent_lines:\n",
        "                    full_response = \"\\n\".join(agent_lines)\n",
        "                    chat_history.append({'role': 'agent', 'content': full_response})\n",
        "\n",
        "                # Show chat without status (Input box will appear below)\n",
        "                render_chat(chat_history, status=None)\n",
        "                time.sleep(0.1)\n",
        "\n",
        "                try:\n",
        "                    user_input = input(\"Type your input here: \")\n",
        "                except KeyboardInterrupt:\n",
        "                    print(\"\\nStopped.\")\n",
        "                    break\n",
        "\n",
        "                chat_history.append({'role': 'user', 'content': user_input})\n",
        "                last_user_input = user_input\n",
        "\n",
        "                # Show \"Agent is replying...\" and hide input\n",
        "                render_chat(chat_history, status=\"üü¢ Agent is replying...\")\n",
        "\n",
        "                child.send(user_input + \"\\n\")\n",
        "\n",
        "            elif index == 1: # EOF\n",
        "                chat_history.append({'role': 'sys', 'content': \"üî¥ Session ended.\"})\n",
        "                render_chat(chat_history)\n",
        "                break\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        child.close()\n",
        "        print(\"Chat closed.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EARMvk_Tdwfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have this function, we can go ahead and call our first agent. In order to call an agent using the `adk run` command, we need to pass the path to the parent directory of that agent to this command. Run the following cell and start talking with our very first agent!"
      ],
      "metadata": {
        "id": "IhDUEKGLDp2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Part 1 agent|\n",
        "\n",
        "chat_with_agent_clean('agents/part1/basic_radiology_assistant', session_id=\"123\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9tdIEslxDpY3",
        "outputId": "b2d095ad-83c3-4431-92b0-259d2854ad5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .chat-container { max-width: 700px; margin: 0 auto; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }\n",
              "            .agent-row { display: flex; margin-bottom: 20px; align-items: flex-start; }\n",
              "            .user-row { display: flex; margin-bottom: 20px; justify-content: flex-end; align-items: flex-end; }\n",
              "            .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }\n",
              "            .avatar-agent { background: #f0f0f0; margin-right: 15px; margin-top: 5px; }\n",
              "            .avatar-user { background: #e3f2fd; margin-left: 15px; }\n",
              "            .agent-bubble { background-color: #f8f9fa; color: #1a1a1a; padding: 15px 22px; border-radius: 20px; border-top-left-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }\n",
              "            .user-bubble { background-color: #007bff; color: white; padding: 15px 22px; border-radius: 20px; border-bottom-right-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; text-align: left; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }\n",
              "            \n",
              "            /* Markdown Styles */\n",
              "            .agent-bubble p { margin: 0 0 10px 0; } .agent-bubble p:last-child { margin: 0; }\n",
              "            .agent-bubble ul, .agent-bubble ol { margin: 5px 0 10px 20px; padding: 0; }\n",
              "            .agent-bubble li { margin-bottom: 5px; }\n",
              "            .agent-bubble strong { font-weight: 700; color: #000; }\n",
              "            .agent-bubble pre { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 8px; overflow-x: auto; }\n",
              "            .agent-bubble code { background: #eee; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }\n",
              "            .agent-bubble pre code { background: transparent; padding: 0; color: #f8f8f2; }\n",
              "            \n",
              "            .status-indicator { font-size: 13px; color: #888; text-align: center; margin-top: 20px; font-style: italic; animation: pulse 1.5s infinite; }\n",
              "            @keyframes pulse { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }\n",
              "            .sys-log { font-family: monospace; font-size: 11px; color: #aaa; margin: 5px 0; text-align: center; }\n",
              "        </style>\n",
              "        \n",
              "        <div class=\"chat-container\">\n",
              "            <h2 style=\"color: #333; margin-bottom: 5px; text-align: center;\">ü©∫ Part 1: Basic Radiology Assistant</h2>\n",
              "            <p style=\"font-size: 13px; margin-top: 0; text-align: center;\"><span style=\"color: #d9534f; font-weight: bold; margin-left: 10px;\">üî¥ Recording Session: 123</span></p>\n",
              "            <hr style=\"border: 0; border-top: 1px solid #eee; margin-bottom: 30px;\">\n",
              "        <div class=\"sys-log\">Log setup complete: /tmp/agents_log/agent.20251122_220042.log</div><div class=\"sys-log\">To access latest log: tail -F /tmp/agents_log/agent.latest.log</div><div class=\"sys-log\">Running agent basic_radiology_assistant, type exit to exit.</div><div class=\"user-row\"><div class=\"user-bubble\">Hi</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"agent-row\"><div class=\"avatar avatar-agent\">ü§ñ</div><div class=\"agent-bubble\"><p>Hello! I'm here to answer your questions about radiology. How can I assist you today?</p></div></div><div class=\"user-row\"><div class=\"user-bubble\">Is radiology a good specialty for residency?</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"agent-row\"><div class=\"avatar avatar-agent\">ü§ñ</div><div class=\"agent-bubble\"><p>Radiology is often considered a very good specialty for residency, and for a number of reasons that appeal to different individuals. Here are some of the common advantages and aspects that make it attractive:<br />\n",
              "1.  <strong>Intellectual Stimulation:</strong> It's a highly intellectual field that requires a deep understanding of anatomy, pathology, physics (of imaging), and clinical medicine. Radiologists act as consultants to nearly every other specialty.<br />\n",
              "2.  <strong>Breadth of Knowledge:</strong> You get exposure to a vast range of diseases and organ systems, which can be very stimulating if you enjoy broad medical knowledge rather than hyper-specialization in one area.<br />\n",
              "3.  <strong>Technology-Driven:</strong> For those who enjoy working with cutting-edge technology and constantly evolving tools, radiology is an excellent fit.<br />\n",
              "4.  <strong>Work-Life Balance (Relative):</strong> While residency is demanding in any field, the <em>post-residency</em> lifestyle in radiology can often offer a better work-life balance compared to some surgical or very demanding medical specialties, though this varies greatly by practice setting (academic vs. private, subspecialty, call burden).<br />\n",
              "5.  <strong>Procedural Opportunities:</strong> While much of radiology is diagnostic, interventional radiology offers a significant procedural component for those who enjoy hands-on work. Even diagnostic radiologists perform procedures like biopsies, drainages, and line placements.<br />\n",
              "6.  <strong>Demand and Job Market:</strong> Historically, the job market for radiologists has been quite stable and often robust, though it can fluctuate with economic conditions and healthcare trends.<br />\n",
              "7.  <strong>Subspecialization:</strong> Radiology offers numerous subspecialties (e.g., neuroradiology, musculoskeletal, body imaging, pediatric, interventional, breast imaging), allowing you to focus on an area of particular interest after general training.<br />\n",
              "However, like any specialty, it also has its challenges:<br />\n",
              "*   <strong>Long Training:</strong> Diagnostic radiology residency is typically 5 years (including an intern year), and interventional radiology is even longer (6 years).<br />\n",
              "*   <strong>Intense Learning Curve:</strong> The sheer volume of information to learn, from normal anatomy to countless pathologies across all modalities, is immense.<br />\n",
              "*   <strong>Limited Direct Patient Contact:</strong> If you are drawn to medicine primarily for direct, long-term patient interaction and relationship building, diagnostic radiology might feel less fulfilling as much of the work is done in front of a computer screen.<br />\n",
              "*   <strong>Sedentary Nature:</strong> It can be a very sedentary job, sitting for long hours interpreting studies.<br />\n",
              "Ultimately, whether radiology is a \"good\" specialty depends on your personal interests, strengths, and career goals. If you enjoy problem-solving, technology, complex visual information, and a broad understanding of disease, it can be an incredibly rewarding career.</p></div></div><div class=\"user-row\"><div class=\"user-bubble\">exit</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"sys-log\">üî¥ Session ended.</div></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3\\. Exploring the Session Details**\n",
        "\n",
        "Great! Did you have fun with this first agent? Before we proceed forward, Did you notice that we actually also passed a session ID to our chat function? This is because the `adk run` command optionally accepts a `session ID` argument and when you pass that, It logs down all the details of the conversation in a JSON file.\n",
        "\n",
        "Pause for a second and take a look at The JSON file which was saved inside the basic radiology assistant agent folder. There are many keys and values in this file. What do you think this data is about?\n",
        "\n",
        "Well, actually this JSON file shows the great amount of **logging** that the Google ADK framework does behind the scenes when you execute an agent. For example:\n",
        "\n",
        "- **Events** are referring to anything that might have happened since the time that you started your agent‚Äîany kind of task that you assigned to that agent, what that agent replied to, how many tokens it used, what kind of modality your input and output data had\n",
        "- **Artifacts** might include images, videos, or voice commands that needed to be stored\n",
        "- **Memory** tracks variables that the agent should have kept in its memory\n",
        "- **Sessions** are individual instances of agent activity. Agents in Google ADK can engage in **multiple simultaneous conversations** with different users (or take actions on their behalves), where each user has its own session. Therefore, keeping track of which sessions are currently active, who has spoken with the agent, and how events and states have evolved in each session is another fundamental aspect of the Google ADK framework that makes it an ideal choice for web service applications that can later be served to **FastAPI** or other backend-to-framework communication protocols."
      ],
      "metadata": {
        "id": "7t8J3jfWsWxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2. Augmented Language Models**\n",
        "\n",
        "> Associated Agent: **web_search_agent**\n",
        "\n",
        "Even though we called our dummy radiology assistant an \"agent,\" in reality it was just a simple, naive large language model. Well, let's improve it a little bit!\n",
        "\n",
        "What we can do with Google ADK is to equip our agents *(note that here we are using the term \"agent\" a little bit loosely)* with different **tools**.\n",
        "\n",
        "---\n",
        "\n",
        "### What Are Tools?\n",
        "\n",
        "Tools can be defined very broadly, but in simple terms, a **tool** is a programming interface that allows the agent to achieve something that it could not achieve‚Äîor could not perform well‚Äîon its own.\n",
        "\n",
        "For example, Google ADK itself has a very useful built-in tool that almost all agents might benefit from, and that is **Google Search**. Well, at the end of the day, ADK belongs to the company owning our beloved Google Search! So you can easily equip any agent with a Google Search toolbox that it can use to programmatically search for whatever it needs to satisfy you as the user commanding that agent.\n",
        "\n",
        "---\n",
        "\n",
        "### Other Built-in Tools\n",
        "\n",
        "Google has some other built-in tools as well, the most important of which (in addition to Google Search) is **Code Execution**, which enables an agent to write and execute programming code. Even though this tool is also very important, we will not talk about it in this notebook and instead stick to the Google Search tool.\n",
        "\n",
        "---\n",
        "\n",
        "In the following code snippet, you can see the code for a simple web search agent that has different instructions compared to the prior agent we coded, and this time is equipped with the Google Search tool imported from Google ADK.RetryClaude can make mistakes. Please double-check responses.\n",
        "\n",
        "```python\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.tools import google_search\n",
        "\n",
        "root_agent = Agent(\n",
        "    name=\"web_search_agent\",\n",
        "    model=\"gemini-2.5-flash\",  # Using Gemini Flash model\n",
        "    instruction=(\n",
        "        \"You are a specialized radiology assistant that uses web search to answer questions. \"\n",
        "        \"Your primary role is to answer questions about radiology by performing web searches, including:\\n\"\n",
        "        \"- Medical imaging techniques and modalities\\n\"\n",
        "        \"- Radiological findings and interpretations\\n\"\n",
        "        \"- Anatomy and pathology relevant to radiology\\n\"\n",
        "        \"- Imaging protocols and best practices\\n\"\n",
        "        \"- Radiological terminology and concepts\\n\"\n",
        "        \"- Recent research and developments in radiology\\n\"\n",
        "        \"- Clinical guidelines and recommendations\\n\\n\"\n",
        "        \"When answering radiology questions:\\n\"\n",
        "        \"- Use the google_search tool to find up-to-date and accurate information\\n\"\n",
        "        \"- Synthesize information from multiple sources when available\\n\"\n",
        "        \"- Provide clear, accurate, and well-sourced answers\\n\"\n",
        "        \"- Cite relevant sources when appropriate\\n\\n\"\n",
        "        \"You should politely decline to answer questions that are not related to radiology. \"\n",
        "        \"When asked about non-radiology topics, kindly redirect the conversation back to \"\n",
        "        \"radiology-related questions and explain that you specialize only in radiology topics.\"\n",
        "    ),\n",
        "    description=(\n",
        "        \"A specialized radiology assistant that answers questions by performing web searches. \"\n",
        "        \"Uses Google Search to provide up-to-date information about radiology topics and \"\n",
        "        \"avoids answering questions unrelated to radiology.\"\n",
        "    ),\n",
        "    tools=[google_search],  # Equipped with Google Search tool\n",
        ")\n",
        "```\n"
      ],
      "metadata": {
        "id": "LQxd4evltZtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to interact with the above agent. Try to challenge this agent to ensure it is answering you by grounding in facts retrieved from internet. For example, you can ask it about recent events and things that the Gemini model might not have known until very recently.  "
      ],
      "metadata": {
        "id": "a9jdNEvAulvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Part 2 agent\n",
        "\n",
        "chat_with_agent_clean('agents/part2/web_search_agent', session_id=\"123\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "po-CPzssJyFM",
        "outputId": "6a90c40f-ea91-4d70-b76d-4ca422c4a865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .chat-container { max-width: 700px; margin: 0 auto; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }\n",
              "            .agent-row { display: flex; margin-bottom: 20px; align-items: flex-start; }\n",
              "            .user-row { display: flex; margin-bottom: 20px; justify-content: flex-end; align-items: flex-end; }\n",
              "            .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }\n",
              "            .avatar-agent { background: #f0f0f0; margin-right: 15px; margin-top: 5px; }\n",
              "            .avatar-user { background: #e3f2fd; margin-left: 15px; }\n",
              "            .agent-bubble { background-color: #f8f9fa; color: #1a1a1a; padding: 15px 22px; border-radius: 20px; border-top-left-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }\n",
              "            .user-bubble { background-color: #007bff; color: white; padding: 15px 22px; border-radius: 20px; border-bottom-right-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; text-align: left; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }\n",
              "            \n",
              "            /* Markdown Styles */\n",
              "            .agent-bubble p { margin: 0 0 10px 0; } .agent-bubble p:last-child { margin: 0; }\n",
              "            .agent-bubble ul, .agent-bubble ol { margin: 5px 0 10px 20px; padding: 0; }\n",
              "            .agent-bubble li { margin-bottom: 5px; }\n",
              "            .agent-bubble strong { font-weight: 700; color: #000; }\n",
              "            .agent-bubble pre { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 8px; overflow-x: auto; }\n",
              "            .agent-bubble code { background: #eee; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }\n",
              "            .agent-bubble pre code { background: transparent; padding: 0; color: #f8f8f2; }\n",
              "            \n",
              "            .status-indicator { font-size: 13px; color: #888; text-align: center; margin-top: 20px; font-style: italic; animation: pulse 1.5s infinite; }\n",
              "            @keyframes pulse { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }\n",
              "            .sys-log { font-family: monospace; font-size: 11px; color: #aaa; margin: 5px 0; text-align: center; }\n",
              "        </style>\n",
              "        \n",
              "        <div class=\"chat-container\">\n",
              "            <h2 style=\"color: #333; margin-bottom: 5px; text-align: center;\">ü©∫ Part 2: Web Search Assistant</h2>\n",
              "            <p style=\"font-size: 13px; margin-top: 0; text-align: center;\"><span style=\"color: #d9534f; font-weight: bold; margin-left: 10px;\">üî¥ Recording Session: 123</span></p>\n",
              "            <hr style=\"border: 0; border-top: 1px solid #eee; margin-bottom: 30px;\">\n",
              "        <div class=\"sys-log\">Log setup complete: /tmp/agents_log/agent.20251122_220148.log</div><div class=\"sys-log\">To access latest log: tail -F /tmp/agents_log/agent.latest.log</div><div class=\"sys-log\">Running agent web_search_agent, type exit to exit.</div><div class=\"user-row\"><div class=\"user-bubble\">Today is November 22, 2025. What has happened in the past week in radiology? </div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"agent-row\"><div class=\"avatar avatar-agent\">ü§ñ</div><div class=\"agent-bubble\"><p>In the past week, radiology has seen significant advancements and discussions across several key areas, including artificial intelligence (AI) integration, novel imaging techniques, enhanced reporting solutions, and ongoing challenges related to the workforce.<br />\n",
              "<strong>Artificial Intelligence (AI) and Machine Learning:</strong><br />\n",
              "AI continues to be a transformative force in radiology, with a strong focus on improving efficiency, accuracy, and patient outcomes. Many radiologists (85%) express optimism about AI's potential to enhance patient care.<br />\n",
              "*   <strong>Accelerating Workflows and Reducing Burden:</strong> AI-enabled systems are being utilized to accelerate image acquisition and reconstruction, potentially allowing for more studies per day and providing radiologists with higher-quality data sooner. These systems also aim to reduce the administrative burden on radiologists, freeing them to concentrate on image interpretation and patient communication.<br />\n",
              "*   <strong>Enhanced Reporting:</strong> New technologies like Scriptor Software's rScriptor SmartMacros, introduced this week, enable radiologists to populate multiple report sections with a single macro, embedding numerical data and text. These SmartMacros can automatically insert appropriate ACR Incidental Findings follow-up recommendations, reducing dictation time and improving consistency. Additionally, Mosaic Clinical Technologies, through its acquisition of Cognita Imaging Inc., launched Mosaic Drafting‚Ñ¢, an AI solution that generates preliminary drafts for X-rays and head CTs, demonstrating improved detection rates and efficiency. While large language models (LLMs) can simplify oncologic CT reports for patients to improve comprehension, radiologist oversight remains crucial to address potential clinical errors.<br />\n",
              "*   <strong>Advanced Detection and Screening:</strong> Research published in Nature Scientific Reports highlighted an AI algorithm from Riverain Technologies that can calculate coronary artery calcium scores from non-contrast CT scans with performance comparable to radiologists, advancing opportunistic screening. RadNet also launched an AI-enabled breast cancer detection service that incorporates an AI-driven review for suspicious findings and personalized risk assessment. Furthermore, mammography radiomic models have shown promise in predicting occult invasive breast cancer in women with confirmed ductal carcinoma in situ (DCIS).<br />\n",
              "*   <strong>Image Enhancement:</strong> Bracco Imaging announced ANVISA clearance in Brazil for AiMIFY‚Ñ¢, an AI technology that amplifies contrast enhancement in brain MRI scans. This innovation aims to provide radiologists with improved contrast information, particularly aiding in the visualization of small and poorly enhanced lesions.<br />\n",
              "*   <strong>Generative AI and Foundation Models:</strong> A review published in RSNA Journals explored the evolving role of foundation models (FMs) and generative AI in radiology, discussing their applications in areas like synthetic image generation and multimodal data integration. The review also highlighted the challenges associated with their clinical integration, such as interpretability, potential bias, and privacy concerns.<br />\n",
              "<strong>New Imaging Techniques and Modalities:</strong><br />\n",
              "Innovations in imaging hardware and software continue to push the boundaries of diagnostic capabilities.<br />\n",
              "*   <strong>Photon-Counting Detector CT (PCD-CT):</strong> Emerging research suggests that PCD-CT offers significantly higher accuracy in detecting obstructive coronary artery disease (CAD) compared to traditional energy-integrating CT (EID-CT), potentially leading to a reduction in referrals for invasive coronary angiography. PCD-CT is also being optimized for applications such as rectal cancer T staging. Dunlee announced its participation at RSNA 2025, where it will showcase breakthroughs in Ultra-High Resolution (UHR) and Photon Counting CT.<br />\n",
              "*   <strong>Dynamic Digital Radiography (DDR):</strong> Konica Minolta Healthcare announced that Dynamic Digital Radiography (DDR) will be featured in seven scientific presentations at RSNA 2025. This low-dose digital X-ray advancement allows for the visualization of anatomy in motion and has demonstrated clinical value in diagnosing various conditions, including interstitial lung disease, COPD, lung cancer, and pulmonary thrombo-embolism, often without the need for contrast.<br />\n",
              "*   <strong>Advanced MRI:</strong> New research highlighted C-FLAIR, a fluid-attenuated inversion recovery technique with controlled artifact suppression in brain MRI, which has been shown to reduce artifacts that can mimic hyperintense white matter lesions.<br />\n",
              "*   <strong>Therapeutic Ultrasound:</strong> Stanford researchers have developed a novel, drug-free ultrasound method that successfully removed molecular waste and reduced inflammation in the brains of mice, with plans to translate this approach to human clinical testing for neurological diseases.<br />\n",
              "<strong>Radiation Dose Reduction:</strong><br />\n",
              "Patient safety remains a priority, with several new research studies highlighting improved protocols for reducing CT radiation dose.<br />\n",
              "<strong>Workforce Challenges:</strong><br />\n",
              "The radiology field is actively addressing workforce challenges. A report by the Canadian Association of Medical Radiation Technologists revealed a \"workforce crisis\" due to burnout and a demand for MRI and CT exams that outpaces professional growth, leading to significant vacancy rates. The acquisition of Cognita Imaging Inc. by Mosaic Clinical Technologies aims to address the global radiologist capacity crisis by using AI to expand capacity and enhance clinical performance.<br />\n",
              "<strong>Upcoming Events:</strong><br />\n",
              "The 5th International Conference on Radiology and Diagnostic Imaging is scheduled for November 24-25, 2025, in London, UK, and will focus on the latest breakthroughs and future directions, including the role of AI and digital tools. The Radiological Society of North America (RSNA) 2025 annual meeting is also set to feature numerous presentations on cutting-edge technologies and research.</p></div></div><div class=\"user-row\"><div class=\"user-bubble\">exit</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"sys-log\">üî¥ Session ended.</div></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 3. Custom Tools and ADK Limitations**\n",
        "\n",
        "> Associated Agent: **biogeraphy_agent_broken**\n",
        "\n",
        "All right, now that we saw our very first example of a large language model using tools (AKA an augmented language model), let's see if we can create our own custom tools.\n",
        "\n",
        "Obviously, the answer to this question is positive! In fact, Google ADK and many other agentic frameworks allow you to put together programming functions and simply pass them as tools to an agent.\n",
        "\n",
        "---\n",
        "\n",
        "### Tool Conventions Across Frameworks\n",
        "\n",
        "Now, depending on the agentic framework you are using, you might need to follow different conventions for ensuring that your function tools are compatible with the agents you are using. But almost all of these conventions are minimal and very easy to handle.\n",
        "\n",
        "One of the conventions that almost all agentic frameworks adhere to is to ensure that your custom functions have **very good documentation**. In Python, for example, good documentation means having a very good **docstring** and **type hinting** before anything else.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Documentation Matters for Agents\n",
        "\n",
        "You might wonder why this is necessary. Well, even though good type hinting and docstrings are always recommended to enhance code readability, for agents, it is of **utmost importance**.\n",
        "\n",
        "When an agent wants to identify the right tool among the many tools that it might have for a specific task, the agent cannot read the entire length of the function. Instead, agents go through the **docstring** and **input/output arguments** of a function and try to understand what purpose that function is serving. Then they use it in the right context.\n",
        "\n",
        "---\n",
        "\n",
        "### Building a Biography Agent\n",
        "\n",
        "Enough talking‚Äîlet's go ahead and work on our third agent, which is a **biography agent**.\n",
        "\n",
        "In this agent, we want to:\n",
        "1. Look for a person's biography by searching Google for their name\n",
        "2. Write down the biography we found as a markdown file\n",
        "\n",
        "Even though the agent itself might be able to write very good markdown for us, we can still rely on an external tool to take the agent's input and write it as a markdown file.\n",
        "\n",
        "The following code snippets show how such a tool can be created and then how we can pass it to an agent.\n",
        "\n",
        "```python\n",
        "from pathlib import Path\n",
        "\n",
        "def write_biography_markdown(biography_content: str, person_name: str, filename: str = None) -> str:\n",
        "    \"\"\"Write a biography to a markdown file.\n",
        "    \n",
        "    This function takes biography content and saves it to a markdown file.\n",
        "    The file will be saved in the same directory as the agent file.\n",
        "    \n",
        "    Args:\n",
        "        biography_content: The biography content in markdown format.\n",
        "        person_name: The name of the person the biography is about.\n",
        "        filename: Optional custom filename. If not provided, uses person_name_biography.md\n",
        "    \n",
        "    Returns:\n",
        "        A string message indicating success and the file path where the markdown was saved.\n",
        "    \n",
        "    Example:\n",
        "        write_biography_markdown(\"# John Doe\\n\\nJohn Doe was born...\", \"John Doe\")\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get the directory where this agent file is located\n",
        "        agent_dir = Path(__file__).parent\n",
        "        \n",
        "        # Generate filename if not provided\n",
        "        if filename is None:\n",
        "            # Sanitize person name for filename\n",
        "            safe_name = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '' for c in person_name)\n",
        "            safe_name = safe_name.replace(' ', '_').lower()\n",
        "            filename = f\"{safe_name}_biography.md\"\n",
        "        \n",
        "        # Ensure .md extension\n",
        "        if not filename.endswith('.md'):\n",
        "            filename = f\"{filename}.md\"\n",
        "        \n",
        "        markdown_path = agent_dir / filename\n",
        "        \n",
        "        # Write markdown file\n",
        "        with open(markdown_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(biography_content)\n",
        "        \n",
        "        return (\n",
        "            f\"Successfully created biography markdown file for {person_name}. \"\n",
        "            f\"File saved at: {markdown_path.absolute()}\"\n",
        "        )\n",
        "    \n",
        "    except Exception as e:\n",
        "        return f\"Error creating markdown file: {str(e)}\"\n",
        "```\n",
        "\n",
        "And here is our agent:\n",
        "\n",
        "```python\n",
        "root_agent = Agent(\n",
        "    name=\"biography_agent_broken\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    instruction=(\n",
        "        \"You are a biography writer agent. Your role is to research people and write their biographies.\\n\\n\"\n",
        "        \n",
        "        \"When given a person's name:\\n\"\n",
        "        \"1. Use the google_search tool to search for information about the person.\\n\"\n",
        "        \"2. Gather comprehensive information including:\\n\"\n",
        "        \"   - Early life and background\\n\"\n",
        "        \"   - Education\\n\"\n",
        "        \"   - Career and achievements\\n\"\n",
        "        \"   - Notable works or contributions\\n\"\n",
        "        \"   - Personal life (if relevant and publicly available)\\n\"\n",
        "        \"   - Awards and recognition\\n\"\n",
        "        \"   - Current status or legacy\\n\\n\"\n",
        "        \"3. Synthesize the information into a well-structured biography in markdown format.\\n\"\n",
        "        \"4. Use the write_biography_markdown function to save the biography to a markdown file.\\n\\n\"\n",
        "        \n",
        "        \"The biography should be:\\n\"\n",
        "        \"- Well-organized with clear sections\\n\"\n",
        "        \"- Factual and accurate\\n\"\n",
        "        \"- Properly formatted in markdown\\n\"\n",
        "        \"- Include sources when possible\\n\"\n",
        "        \"- Professional and engaging\\n\\n\"\n",
        "        \n",
        "        \"Example markdown structure:\\n\"\n",
        "        \"# [Person's Name]\\n\\n\"\n",
        "        \"## Early Life\\n\\n\"\n",
        "        \"## Education\\n\\n\"\n",
        "        \"## Career\\n\\n\"\n",
        "        \"## Achievements\\n\\n\"\n",
        "        \"## Personal Life\\n\\n\"\n",
        "        \"## Legacy\\n\\n\"\n",
        "    ),\n",
        "    description=(\n",
        "        \"A biography writer that searches the internet for information about people \"\n",
        "        \"and writes their biographies in markdown files. \"\n",
        "        \"BROKEN: This agent mixes Google Search tool with custom function tools in a single agent.\"\n",
        "    ),\n",
        "    tools=[\n",
        "        google_search,  # Google Search tool\n",
        "        tools.write_biography_markdown,  # Custom markdown writing function\n",
        "    ],\n",
        ")\n",
        "\n",
        "```\n",
        "\n",
        "Great, now let's go ahead and execute it!"
      ],
      "metadata": {
        "id": "dqZV8Iv_PXiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Part 3 agent\n",
        "\n",
        "chat_with_agent_clean('agents/part3/biography_agent_broken')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "mG4Ot7CeP-oJ",
        "outputId": "ef4a5d47-ac5b-4a46-f4d5-8b7640ec0527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .chat-container { max-width: 700px; margin: 0 auto; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }\n",
              "            .agent-row { display: flex; margin-bottom: 20px; align-items: flex-start; }\n",
              "            .user-row { display: flex; margin-bottom: 20px; justify-content: flex-end; align-items: flex-end; }\n",
              "            .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }\n",
              "            .avatar-agent { background: #f0f0f0; margin-right: 15px; margin-top: 5px; }\n",
              "            .avatar-user { background: #e3f2fd; margin-left: 15px; }\n",
              "            .agent-bubble { background-color: #f8f9fa; color: #1a1a1a; padding: 15px 22px; border-radius: 20px; border-top-left-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }\n",
              "            .user-bubble { background-color: #007bff; color: white; padding: 15px 22px; border-radius: 20px; border-bottom-right-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; text-align: left; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }\n",
              "            \n",
              "            /* Markdown Styles */\n",
              "            .agent-bubble p { margin: 0 0 10px 0; } .agent-bubble p:last-child { margin: 0; }\n",
              "            .agent-bubble ul, .agent-bubble ol { margin: 5px 0 10px 20px; padding: 0; }\n",
              "            .agent-bubble li { margin-bottom: 5px; }\n",
              "            .agent-bubble strong { font-weight: 700; color: #000; }\n",
              "            .agent-bubble pre { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 8px; overflow-x: auto; }\n",
              "            .agent-bubble code { background: #eee; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }\n",
              "            .agent-bubble pre code { background: transparent; padding: 0; color: #f8f8f2; }\n",
              "            \n",
              "            .status-indicator { font-size: 13px; color: #888; text-align: center; margin-top: 20px; font-style: italic; animation: pulse 1.5s infinite; }\n",
              "            @keyframes pulse { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }\n",
              "            .sys-log { font-family: monospace; font-size: 11px; color: #aaa; margin: 5px 0; text-align: center; }\n",
              "        </style>\n",
              "        \n",
              "        <div class=\"chat-container\">\n",
              "            <h2 style=\"color: #333; margin-bottom: 5px; text-align: center;\">ü©∫ Part 3: Biography Agent</h2>\n",
              "            <p style=\"font-size: 13px; margin-top: 0; text-align: center;\"><span style=\"color: #888;\">Interactive ADK Session</span></p>\n",
              "            <hr style=\"border: 0; border-top: 1px solid #eee; margin-bottom: 30px;\">\n",
              "        <div class=\"sys-log\">Log setup complete: /tmp/agents_log/agent.20251122_220447.log</div><div class=\"sys-log\">To access latest log: tail -F /tmp/agents_log/agent.latest.log</div><div class=\"sys-log\">Running agent biography_agent_broken, type exit to exit.</div><div class=\"user-row\"><div class=\"user-bubble\">Cooky Menias</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"sys-log\">üî¥ Session ended.</div></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding Agent Failures and Framework Limitations\n",
        "\n",
        "Well, what happened? Why did our agent not work and our session ended prematurely?\n",
        "\n",
        "As you can imagine from the title of this part (Agent Failure), the failure of this agent was not unexpected. Actually, we **purposefully ignored a bug** in how we set up our agent above to teach you something about the Google ADK framework.\n",
        "\n",
        "---\n",
        "\n",
        "### Framework Restrictions\n",
        "\n",
        "Like almost every other framework that deals with language models, Google ADK comes with lots of restrictions. And because ADK targets deployment and production readiness, some of these restrictions are very strictly enforced for developers.\n",
        "\n",
        "For example, one of the interesting restrictions that this package has is that its **native tools** (such as Google Search or Code Execution) **cannot coexist with custom tools** that the user has developed and wants the agent to use.\n",
        "\n",
        "This means that when we were trying to pass:\n",
        "```python\n",
        "tools=[\n",
        "    google_search,  # Google Search tool\n",
        "    tools.write_biography_markdown,  # Custom markdown writing function\n",
        "],\n",
        "```\n",
        "\n",
        "we violated one of the limitations of Google ADK. These two tools cannot be passed at the same time to an agent.\n",
        "\n",
        "---\n",
        "\n",
        "### Why These Restrictions Exist\n",
        "\n",
        "Now you might wonder why this is the case. Honestly, we don't have a clear answer for you, but you are more than welcome to dig deeper into this‚Äîmaybe submit an issue to the GitHub page of Google ADK or try to understand from other sources why they made such a decision.\n",
        "\n",
        "What we have generally read here and there is that these restrictions mostly come from optimizing deployment and production readiness. But no one knows if this really is the case, or if these things are going to change in the near or far future.\n",
        "\n",
        "---\n",
        "\n",
        "### The Key Takeaway\n",
        "\n",
        "For now, what matters is that we should **familiarize ourselves with Google ADK** (or any other framework we are working with) and study the documentation well‚Äîso we don't spend hours and hours figuring out a bug that does not appear clear at first glance.\n",
        "\n",
        "With all the above said, let's move forward and fix the agent that we coded before."
      ],
      "metadata": {
        "id": "3Rl3OchmR8PU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 4. An Introduction to Multiagent Frameworks**\n",
        "\n",
        "> Associated Agent: **biogeraphy_agent**\n",
        "\n",
        "Alright, if we can't pass two tools of different types to a single agent, then the obvious alternative is to have **two agents that collaborate with each other**, where each uses one of the tools. That's exactly what we are going to do in this part, and that's our introduction to the concept of **multi-agent frameworks**.\n",
        "\n",
        "---\n",
        "\n",
        "### Why Multi-Agent Systems?\n",
        "\n",
        "To be honest with you, even though an agent that can take many actions and use many tools on its own is a very exciting concept, a far more exciting concept for many developers are **multi-agent pipelines**. These pipelines leverage the power of more than one agent to achieve things that a single agent might not be able to do‚Äîor might not be able to do with good quality.\n",
        "\n",
        "Now, some people look at multi-agent systems as very powerful workflows that can achieve superhuman results, advance science, and solve complex problems. Others look at them as an army of minions that may or may not be able to handle and automate some of the difficulties we have in our day-to-day life and practice.\n",
        "\n",
        "Regardless of whichever camp you belong to, it is still good to understand the basics of how to connect two agents to each other.\n",
        "\n",
        "---\n",
        "\n",
        "### Three Main Multi-Agent Patterns in Google ADK\n",
        "\n",
        "In the Google ADK framework, connection of agents to each other follows one of three main patterns:\n",
        "\n",
        "**1. Sequential Pipeline:** As the name implies, a combination of two or more agents that are called one after the other, where the output of each may or may not be the input of the subsequent agents.\n",
        "\n",
        "<img src=\"https://google.github.io/adk-docs/assets/sequential-agent.png\" width=\"600\" alt=\"Sequential Agent Pattern\">\n",
        "\n",
        "**2. Parallel Pipeline:** A setup where multiple agents are called to work on different aspects of the same problem at the same time. Notably, these aspects should be independent from each other‚Äîneither agent has access to the inputs or outputs of the other agents.\n",
        "\n",
        "<img src=\"https://google.github.io/adk-docs/assets/parallel-agent.png\" width=\"600\" alt=\"Parallel Agent Pattern\">\n",
        "\n",
        "**3. Loop Agent:** An agent that keeps doing whatever it has been doing until a specific set of checkpoints have been met. You may wonder, \"wasn't this supposed to be a multi-agent entity? Why are we talking about a single agent?\" Because a loop agent usually acts as the **organizer** or **gatekeeper** of multiple agents working at the same time.\n",
        "\n",
        "<img src=\"https://google.github.io/adk-docs/assets/loop-agent.png\" width=\"600\" alt=\"Loop Agent Pattern\">\n",
        "\n",
        "As we will see in the next examples, Google ADK enables you to wrap agents‚Äîand even multi-agent pipelines‚Äîunder other agents or multi-agent pipelines. For example, imagine a sequential pipeline of agents that are all introduced as sub-agents to a loop agent, meaning that loop agent is going to keep calling this sequential pipeline until the desired outcome has been achieved.\n",
        "\n",
        "---\n",
        "\n",
        "### Solving Our Biography Agent Problem\n",
        "\n",
        "Now, let us not confuse you. For this immediate problem that we have on our hands, the solution is very simple.\n",
        "\n",
        "We are going to use a **SequentialAgent** from Google ADK that accepts a name and description as before, but unlike the prior agents we had, will **not receive direct instructions**. The reason is that even though this type of agent is named \"sequential agent,\" it is not a real agent but mostly an agent whose task is to pass its inputs through a chain of sub-agents that it has.\n",
        "\n",
        "Let's take a look at the root agent we can define for our biography agent:\n",
        "```python\n",
        "from google.adk.agents import SequentialAgent\n",
        "from .sub_agents import research_agent, writing_agent\n",
        "\n",
        "# Create sequential workflow: Research first, then write\n",
        "root_agent = SequentialAgent(\n",
        "    name=\"biography_agent\",\n",
        "    description=(\n",
        "        \"A sequential workflow that researches people using Google Search, \"\n",
        "        \"then writes their biographies in markdown files. \"\n",
        "        \"Uses separate agents for research and writing to avoid tool conflicts.\"\n",
        "    ),\n",
        "    sub_agents=[research_agent, writing_agent],\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Understanding Sub-Agents\n",
        "\n",
        "As you can see here, we are passing two separate agents as sub-agents to this sequential agent. Now, you have already seen how the research agent and writing agent will operate *(feel free to check their source code again)*. Those two agents have nothing new‚Äîin fact, each of them is using a separate tool:\n",
        "\n",
        "- The **research agent** uses the Google Search tool to look up a person\n",
        "- The **writing agent** uses a markdown tool to write up the biography about that person\n",
        "\n",
        "The combination of these is passed to this new sequential agent we have here.\n",
        "\n",
        "**Important:** The order of the list you pass as `sub_agents` matters the most, because it defines which agent is going to receive the task first and then hand over to whom. In our case, the research agent does the first task and then the writing agent finishes it up.\n",
        "\n",
        "---\n",
        "\n",
        "### Code Organization Best Practices\n",
        "\n",
        "Another important point to keep in mind: notice how we imported the agents in a relative manner from the `sub_agents` directory. This is another convention in Google ADK that matters a lot.\n",
        "\n",
        "Whenever you are dealing with sub-agents and complicated multi-agent frameworks, it's better to rely as much as you can on the **hierarchy of files and folders** for your agents and sub-agents. Not only does Google ADK work best with this format, but it is also the most clear way of representing multi-agent pipelines in code.\n",
        "\n",
        "As you will soon realize, these multi-agent pipelines tend to get confusing very quickly.\n",
        "\n",
        "---\n",
        "\n",
        "Enough talking! Take a look at the scripts of Part 4, and whenever you are ready, go ahead and try out our multi-agent pipeline in the next cell."
      ],
      "metadata": {
        "id": "VKfLJSkfTMP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Part 4 agent\n",
        "\n",
        "chat_with_agent_clean('agents/part4/biography_agent', session_id='123')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IUCdd5wER0tM",
        "outputId": "c337f2db-9bce-464e-e58f-cd4ba18cde30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .chat-container { max-width: 700px; margin: 0 auto; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }\n",
              "            .agent-row { display: flex; margin-bottom: 20px; align-items: flex-start; }\n",
              "            .user-row { display: flex; margin-bottom: 20px; justify-content: flex-end; align-items: flex-end; }\n",
              "            .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }\n",
              "            .avatar-agent { background: #f0f0f0; margin-right: 15px; margin-top: 5px; }\n",
              "            .avatar-user { background: #e3f2fd; margin-left: 15px; }\n",
              "            .agent-bubble { background-color: #f8f9fa; color: #1a1a1a; padding: 15px 22px; border-radius: 20px; border-top-left-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }\n",
              "            .user-bubble { background-color: #007bff; color: white; padding: 15px 22px; border-radius: 20px; border-bottom-right-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; text-align: left; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }\n",
              "            \n",
              "            /* Markdown Styles */\n",
              "            .agent-bubble p { margin: 0 0 10px 0; } .agent-bubble p:last-child { margin: 0; }\n",
              "            .agent-bubble ul, .agent-bubble ol { margin: 5px 0 10px 20px; padding: 0; }\n",
              "            .agent-bubble li { margin-bottom: 5px; }\n",
              "            .agent-bubble strong { font-weight: 700; color: #000; }\n",
              "            .agent-bubble pre { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 8px; overflow-x: auto; }\n",
              "            .agent-bubble code { background: #eee; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }\n",
              "            .agent-bubble pre code { background: transparent; padding: 0; color: #f8f8f2; }\n",
              "            \n",
              "            .status-indicator { font-size: 13px; color: #888; text-align: center; margin-top: 20px; font-style: italic; animation: pulse 1.5s infinite; }\n",
              "            @keyframes pulse { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }\n",
              "            .sys-log { font-family: monospace; font-size: 11px; color: #aaa; margin: 5px 0; text-align: center; }\n",
              "        </style>\n",
              "        \n",
              "        <div class=\"chat-container\">\n",
              "            <h2 style=\"color: #333; margin-bottom: 5px; text-align: center;\">ü©∫ Part 4: Biography Agent (Fixed)</h2>\n",
              "            <p style=\"font-size: 13px; margin-top: 0; text-align: center;\"><span style=\"color: #d9534f; font-weight: bold; margin-left: 10px;\">üî¥ Recording Session: 123</span></p>\n",
              "            <hr style=\"border: 0; border-top: 1px solid #eee; margin-bottom: 30px;\">\n",
              "        <div class=\"sys-log\">Log setup complete: /tmp/agents_log/agent.20251122_220511.log</div><div class=\"sys-log\">To access latest log: tail -F /tmp/agents_log/agent.latest.log</div><div class=\"sys-log\">Running agent biography_agent, type exit to exit.</div><div class=\"user-row\"><div class=\"user-bubble\">Cooky Menias</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"agent-row\"><div class=\"avatar avatar-agent\">ü§ñ</div><div class=\"agent-bubble\"><p>Christine O. \"Cooky\" Menias, MD, is an American radiologist renowned for her significant contributions to the field of abdominal radiology and oncologic imaging. She is a distinguished educator, author, and leader in various prestigious radiology societies.<br />\n",
              "<strong>Early Life and Background</strong><br />\n",
              "Born in Cairo, Egypt, Christine Menias's family immigrated to England shortly after her birth, where her father completed his urology residency. The family later moved to the United States, settling in Milwaukee, where her father undertook an anesthesiology residency. The family subsequently moved to Chicago, where they continue to reside.<br />\n",
              "<strong>Education</strong><br />\n",
              "Dr. Menias received her undergraduate degree in biology and French from Marquette University in 1990, during which she also studied abroad in France. She obtained her M.D. degree from the George Washington University School of Medicine in 1995. Following medical school, she completed her residency and an abdominal imaging fellowship at the Mallinckrodt Institute of Radiology (MIR) at Washington University School of Medicine in St. Louis. Initially, she had considered a career in infectious disease after volunteering in Kenya and working at a tuberculosis clinic, but later decided to pursue radiology during her fourth year of medical school.<br />\n",
              "<strong>Career and Professional Achievements</strong><br />\n",
              "Dr. Menias began her career in diagnostic radiology as a body imager in the abdominal imaging section at Washington University's Mallinckrodt Institute of Radiology. She served as co-director of Body Computed Tomography and Emergency Radiology and as the assistant residency program director of radiology at the institution, where she currently holds an adjunct professorship.<br />\n",
              "In 2013, after 15 years at Washington University, Dr. Menias joined the Mayo Clinic College of Medicine and Science in Phoenix, Arizona, as a Professor of Radiology. She currently serves as a consultant in the Department of Radiology and is the Chair of the Division of Abdominal Imaging at Mayo Clinic-Arizona. Her special areas of interest within radiology include oncologic, transplant, gynecologic, and emergency radiology.<br />\n",
              "In a significant career milestone, Dr. Menias was announced as the editor of <em>RadioGraphics</em> in January 2021, becoming the journal's first female editor.<br />\n",
              "<strong>Notable Works and Contributions</strong><br />\n",
              "Dr. Menias is internationally recognized for her extensive contributions to abdominal radiology and oncologic imaging. She has authored 6 books, 14 book chapters, and more than 250 peer-reviewed publications, including 71 <em>Radiographic</em> manuscripts. She serves on the editorial boards of several radiology journals and is an associate editor of both <em>RadioGraphics</em> and <em>Abdominal Radiology</em>. She also holds the position of editorial board chair for abdominal imaging for <em>RadioGraphics</em>.<br />\n",
              "Dr. Menias is an active member of numerous prestigious radiology societies, including the Radiological Society of North America (RSNA), the American Roentgen Ray Society (ARRS), and the American Society of Emergency Radiology. She has contributed significantly to ARRS's educational program, delivering numerous instructional courses, review courses, categorical courses, and scientific sessions. She has served as the chair for the Education Exhibits Committee for the RSNA since 2018.<br />\n",
              "<strong>Awards and Recognition</strong><br />\n",
              "Dr. Menias has received numerous accolades for her dedication to radiology education and clinical excellence:<br />\n",
              "*   <strong>ARRS Distinguished Educator:</strong> Named the 2019 ARRS Distinguished Educator.<br />\n",
              "*   <strong>Teacher of the Year Awards:</strong> Multiple \"Teacher of the Year\" honors at Washington University and consecutive \"Teacher of the Year\" awards at Mayo Clinic.<br />\n",
              "*   <strong>Educator of the Year:</strong> Awarded \"Educator of the Year\" by the Department of Radiology at Mayo Clinic.<br />\n",
              "*   <strong>RSNA Honored Educator Award:</strong> Recipient of the RSNA Honored Educator Award for multiple consecutive years.<br />\n",
              "*   <strong>Distinguished Clinician of the Year:</strong> Named the Distinguished Clinician of the Year from Mayo Clinic, Arizona, in 2018.<br />\n",
              "*   <strong>Igor Laufer Visiting Professor:</strong> Selected as the 2016-2017 Igor Laufer Visiting Professor of the Society of Abdominal Radiology.<br />\n",
              "*   <strong>RSNA Cum Laude Awards:</strong> Received multiple RSNA Cum Laude Awards.<br />\n",
              "*   <strong>Alumni Achievement Honoree:</strong> Recognized as a 2020 Alumni Achievement Honoree by Washington University School of Medicine.<br />\n",
              "*   <strong>Certifications:</strong> Diplomate in Radiology of the National Board of Medical Examiners and an examiner for the American Board of Radiology since 2003.<br />\n",
              "<strong>Personal Life</strong><br />\n",
              "Dr. Menias credits her father, a urologist, as her first role model, whose battle with pancreatic cancer deeply influenced her perspective on patient care. She emphasizes the importance of remembering that \"behind every film there's a real patient,\" a philosophy she conveys to her trainees.<br />\n",
              "The biography for Cooky Menias has been successfully saved to <code>/content/agents/part4/biography_agent/cooky_menias_biography.md</code>.</p></div></div><div class=\"user-row\"><div class=\"user-bubble\">exit</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"sys-log\">üî¥ Session ended.</div></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having fun with the agents? Cool! Don't forget to check the **markdown file** that the agentic framework created for you. You can find it under the `part4/biography_agent` folder.\n",
        "\n",
        "Also, certainly take a look at the **session JSON file** that was saved. Do you see how much longer and more detailed this JSON file has become compared to our earlier agents?\n",
        "\n",
        "---\n",
        "\n",
        "### What's Inside the Session JSON?\n",
        "\n",
        "Take a look at it‚Äîit contains:\n",
        "\n",
        "- All the **input data** from you\n",
        "- All the **output data** from the agents\n",
        "- The **intermediate results** between agents\n",
        "- All the **tool calls** that the agents made\n",
        "- The **results** of those tool calls\n",
        "- How the agents called the different tools they had in their arsenal\n",
        "- All with their **token usage** and **timestamps**\n",
        "\n",
        "---\n",
        "\n",
        "Isn't that fascinating? If you were planning to deploy an agent in production, wouldn't you need something this detailed for monitoring, debugging, and optimization?\n",
        "\n",
        "To us, this level of logging and transparency looks like one of the best aspects of Google ADK. It gives you full visibility into what your multi-agent system is doing at every step."
      ],
      "metadata": {
        "id": "yvPWyTCSYXdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 5. Multiagentic Pipelines on Steroid**\n",
        "\n",
        "> Associated Agent: **networking_agent**\n",
        "\n",
        "# Building a Sophisticated Multi-Agent Pipeline\n",
        "\n",
        "Great! Now that we are enjoying multi-agent pipelines, it is time to try a much more sophisticated pipeline so that you can see how we can merge and combine these different sequential, parallel, and loop workflows with each other.\n",
        "\n",
        "For this task, we are not going to explore any new concepts, but we want to demonstrate how you can break a task into multiple subtasks and then delegate it to different agents.\n",
        "\n",
        "---\n",
        "\n",
        "## The Networking Task\n",
        "\n",
        "The task that we want to handle in Part 5 might actually be useful for you. We call it a **networking task**.\n",
        "\n",
        "The ultimate goal of this task is to:\n",
        "\n",
        "1. Take someone's name (who might be a radiologist)\n",
        "2. Pass it to a multi-agent pipeline that will:\n",
        "   - First check if the person is actually a radiologist\n",
        "   - If they are, find some of their most recent and most cited articles\n",
        "   - Gather their background information\n",
        "   - Find URLs that are publicly available about them on the internet (personal websites, social media, scientific portals, etc.)\n",
        "3. At the very end, return the entire output as a nice markdown report\n",
        "\n",
        "---\n",
        "\n",
        "## Pipeline Architecture\n",
        "\n",
        "Take a look at the following diagrams and see if you can understand how we have organized the agents to do this task:\n",
        "\n",
        "### Architecture Diagram\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                         USER INPUT                                      ‚îÇ\n",
        "‚îÇ                    \"Create a networking profile for [Name]\"             ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "                             ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                    ROOT AGENT (SequentialAgent)                         ‚îÇ\n",
        "‚îÇ                    networking_agent                                     ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "                             ‚îÇ Sequential Flow\n",
        "                             ‚îÇ\n",
        "                             ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ              STEP 1: Verification Agent (LlmAgent)                        ‚îÇ\n",
        "‚îÇ              radiologist_verification_agent                               ‚îÇ\n",
        "‚îÇ                                                                           ‚îÇ\n",
        "‚îÇ  Tools: [google_search]                                                   ‚îÇ\n",
        "‚îÇ                                                                           ‚îÇ\n",
        "‚îÇ  Input:  Person's name                                                    ‚îÇ\n",
        "‚îÇ  Output: Background information, verification status, professional details‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "                             ‚îÇ Sequential Flow\n",
        "                             ‚îÇ (Output passed to next agent)\n",
        "                             ‚îÇ\n",
        "                             ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ         STEP 2: Parallel Research Agent (ParallelAgent)                 ‚îÇ\n",
        "‚îÇ         parallel_research_agent                                         ‚îÇ\n",
        "‚îÇ                                                                         ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ\n",
        "‚îÇ  ‚îÇ  URL Finder Agent            ‚îÇ  ‚îÇ  Article Agent               ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ  (LlmAgent)                  ‚îÇ  ‚îÇ  (LlmAgent)                  ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ                              ‚îÇ  ‚îÇ                              ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ  Tools: [google_search]      ‚îÇ  ‚îÇ  Tools: [get_semantic_       ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ                              ‚îÇ  ‚îÇ         scholar_papers]      ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ  Input: Person name +        ‚îÇ  ‚îÇ  Input: Person name +        ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ         background info      ‚îÇ  ‚îÇ         background info      ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ                              ‚îÇ  ‚îÇ                              ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ  Output: List of URLs        ‚îÇ  ‚îÇ  Output: Most recent &       ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ          (social media,      ‚îÇ  ‚îÇ          most cited papers   ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ           personal pages,    ‚îÇ  ‚îÇ          with metadata       ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îÇ           institutional)     ‚îÇ  ‚îÇ                              ‚îÇ     ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n",
        "‚îÇ           ‚îÇ                                    ‚îÇ                        ‚îÇ\n",
        "‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ\n",
        "‚îÇ                          ‚îÇ Parallel Execution                           ‚îÇ\n",
        "‚îÇ                          ‚îÇ (Both agents run simultaneously)             ‚îÇ\n",
        "‚îÇ                          ‚ñº                                              ‚îÇ\n",
        "‚îÇ              Combined Results: URLs + Publications                      ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "                             ‚îÇ Sequential Flow\n",
        "                             ‚îÇ (Combined results passed to formatter)\n",
        "                             ‚îÇ\n",
        "                             ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ              STEP 3: Formatter Agent (LlmAgent)                         ‚îÇ\n",
        "‚îÇ              profile_formatter_agent                                    ‚îÇ\n",
        "‚îÇ                                                                         ‚îÇ\n",
        "‚îÇ  Tools: [] (No tools - structured output only)                          ‚îÇ\n",
        "‚îÇ                                                                         ‚îÇ\n",
        "‚îÇ  Input:  All previous agent outputs:                                    ‚îÇ\n",
        "‚îÇ          - Background information (from verification_agent)             ‚îÇ\n",
        "‚îÇ          - URLs (from url_finder_agent)                                 ‚îÇ\n",
        "‚îÇ          - Publications (from article_agent)                            ‚îÇ\n",
        "‚îÇ                                                                         ‚îÇ\n",
        "‚îÇ  Output: NetworkingProfile (Pydantic model)                             ‚îÇ\n",
        "‚îÇ          - person_name: str                                             ‚îÇ\n",
        "‚îÇ          - background: str                                              ‚îÇ\n",
        "‚îÇ          - online_presence: List[URLInfo]                               ‚îÇ\n",
        "‚îÇ          - recent_publications: PublicationSection                      ‚îÇ\n",
        "‚îÇ            - most_recent_papers: List[Paper]                            ‚îÇ\n",
        "‚îÇ            - most_cited_papers: List[Paper]                             ‚îÇ\n",
        "‚îÇ          - contact_information: Optional[str]                           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "                             ‚îÇ\n",
        "                             ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ                         STRUCTURED OUTPUT                               ‚îÇ\n",
        "‚îÇ                    (NetworkingProfile Pydantic Model)                   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### Data Flow Diagram\n",
        "```\n",
        "User Input\n",
        "    ‚îÇ\n",
        "    ‚îú‚îÄ‚Üí verification_agent\n",
        "    ‚îÇ       ‚îÇ\n",
        "    ‚îÇ       ‚îú‚îÄ‚Üí Uses google_search tool\n",
        "    ‚îÇ       ‚îÇ\n",
        "    ‚îÇ       ‚îî‚îÄ‚Üí Output: Background info\n",
        "    ‚îÇ               ‚îÇ\n",
        "    ‚îÇ               ‚îú‚îÄ‚Üí url_finder_agent (parallel)\n",
        "    ‚îÇ               ‚îÇ       ‚îÇ\n",
        "    ‚îÇ               ‚îÇ       ‚îú‚îÄ‚Üí Uses google_search tool\n",
        "    ‚îÇ               ‚îÇ       ‚îÇ\n",
        "    ‚îÇ               ‚îÇ       ‚îî‚îÄ‚Üí Output: URLs\n",
        "    ‚îÇ               ‚îÇ\n",
        "    ‚îÇ               ‚îî‚îÄ‚Üí article_agent (parallel)\n",
        "    ‚îÇ                       ‚îÇ\n",
        "    ‚îÇ                       ‚îú‚îÄ‚Üí Uses get_semantic_scholar_papers tool\n",
        "    ‚îÇ                       ‚îÇ\n",
        "    ‚îÇ                       ‚îî‚îÄ‚Üí Output: Publications\n",
        "    ‚îÇ                               ‚îÇ\n",
        "    ‚îÇ                               ‚îî‚îÄ‚Üí Combined Results\n",
        "    ‚îÇ                                       ‚îÇ\n",
        "    ‚îÇ                                       ‚îî‚îÄ‚Üí formatter_agent\n",
        "    ‚îÇ                                               ‚îÇ\n",
        "    ‚îÇ                                               ‚îî‚îÄ‚Üí Output: NetworkingProfile (structured)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Hopefully that was not too complicated! The main cornerstone of this setup is that we really want to **break up our tasks into as many smaller subtasks as possible** so that each subtask is easy enough for an agent to handle.\n",
        "\n",
        "---\n",
        "\n",
        "#### Why Break Tasks Into Smaller Pieces?\n",
        "\n",
        "We really don't want to have an agent that is tasked with running many complicated processes. Here's why:\n",
        "\n",
        "1. **Cost Efficiency:** You will need more expensive, larger language models for complex tasks\n",
        "2. **Reliability:** Even with more powerful models, you will still increase the risk of failure\n",
        "\n",
        "---\n",
        "\n",
        "### Design Decisions Explained\n",
        "\n",
        "#### Why Separate Verification and Research?\n",
        "\n",
        "In this case, for example, you might argue that the verification agent and background information agent could be the same agent‚Äîand we agree! However, note that maybe some of the persons whose names we put in this pipeline are **not radiologists**.\n",
        "\n",
        "If that's the case, we don't want the rest of the agentic workflow to be executed for those persons because we will be simply **spending tokens on something that is never going to be useful** for us.\n",
        "\n",
        "#### Why Use Semantic Scholar API Instead of Google Search?\n",
        "\n",
        "You might notice that the article agent is using a relatively sophisticated `get_semantic_scholar_papers` tool even though we could have relied on the Google Search tool for finding papers for someone.\n",
        "\n",
        "That certainly would work, but it's not going to be as accurate as the Semantic Scholar API. However, as we will finally see, the Semantic Scholar API also has its own pitfalls.\n",
        "\n",
        "---\n",
        "\n",
        "#### Let's Test It!\n",
        "\n",
        "Regardless, let's go ahead and run this pipeline and talk afterwards.\n",
        "\n",
        "**Do you have someone in mind to stalk?** Now's the time to give it a try! üòÑ"
      ],
      "metadata": {
        "id": "TsMArMYWYfii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:<br>\n",
        "The Networking agent chatbot works more reliably if you have a Semantic Scholar API key. This key is free and can be obtained through the following link. If you have a key, uncomment the cell below and set it in your notebook."
      ],
      "metadata": {
        "id": "BD1wU_qADVPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.environ['SEMANTIC_SCHOLAR_API_KEY'] = 'YOUR_SEMANTIC_SCHOLAR_API_KEY'"
      ],
      "metadata": {
        "id": "GdT_ndXEDkuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_with_agent_clean('agents/part5/networking_agent', session_id='123')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C8CvtC7GYedG",
        "outputId": "5b3f8677-6ff0-4ac7-ac7c-979ddb6b2408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <style>\n",
              "            .chat-container { max-width: 700px; margin: 0 auto; font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; }\n",
              "            .agent-row { display: flex; margin-bottom: 20px; align-items: flex-start; }\n",
              "            .user-row { display: flex; margin-bottom: 20px; justify-content: flex-end; align-items: flex-end; }\n",
              "            .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-size: 22px; flex-shrink: 0; box-shadow: 0 2px 3px rgba(0,0,0,0.1); }\n",
              "            .avatar-agent { background: #f0f0f0; margin-right: 15px; margin-top: 5px; }\n",
              "            .avatar-user { background: #e3f2fd; margin-left: 15px; }\n",
              "            .agent-bubble { background-color: #f8f9fa; color: #1a1a1a; padding: 15px 22px; border-radius: 20px; border-top-left-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; border: 1px solid #eee; box-shadow: 0 1px 2px rgba(0,0,0,0.05); }\n",
              "            .user-bubble { background-color: #007bff; color: white; padding: 15px 22px; border-radius: 20px; border-bottom-right-radius: 4px; max-width: 80%; line-height: 1.6; font-size: 16px; text-align: left; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }\n",
              "            \n",
              "            /* Markdown Styles */\n",
              "            .agent-bubble p { margin: 0 0 10px 0; } .agent-bubble p:last-child { margin: 0; }\n",
              "            .agent-bubble ul, .agent-bubble ol { margin: 5px 0 10px 20px; padding: 0; }\n",
              "            .agent-bubble li { margin-bottom: 5px; }\n",
              "            .agent-bubble strong { font-weight: 700; color: #000; }\n",
              "            .agent-bubble pre { background: #2d2d2d; color: #ccc; padding: 10px; border-radius: 8px; overflow-x: auto; }\n",
              "            .agent-bubble code { background: #eee; padding: 2px 5px; border-radius: 3px; font-family: monospace; font-size: 0.9em; }\n",
              "            .agent-bubble pre code { background: transparent; padding: 0; color: #f8f8f2; }\n",
              "            \n",
              "            .status-indicator { font-size: 13px; color: #888; text-align: center; margin-top: 20px; font-style: italic; animation: pulse 1.5s infinite; }\n",
              "            @keyframes pulse { 0% { opacity: 0.5; } 50% { opacity: 1; } 100% { opacity: 0.5; } }\n",
              "            .sys-log { font-family: monospace; font-size: 11px; color: #aaa; margin: 5px 0; text-align: center; }\n",
              "        </style>\n",
              "        \n",
              "        <div class=\"chat-container\">\n",
              "            <h2 style=\"color: #333; margin-bottom: 5px; text-align: center;\">ü©∫ Part 5: Networking Agent</h2>\n",
              "            <p style=\"font-size: 13px; margin-top: 0; text-align: center;\"><span style=\"color: #d9534f; font-weight: bold; margin-left: 10px;\">üî¥ Recording Session: 123</span></p>\n",
              "            <hr style=\"border: 0; border-top: 1px solid #eee; margin-bottom: 30px;\">\n",
              "        <div class=\"sys-log\">Log setup complete: /tmp/agents_log/agent.20251122_220605.log</div><div class=\"sys-log\">To access latest log: tail -F /tmp/agents_log/agent.latest.log</div><div class=\"sys-log\">Running agent networking_agent, type exit to exit.</div><div class=\"user-row\"><div class=\"user-bubble\">Pouria Rouzrokh</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"agent-row\"><div class=\"avatar avatar-agent\">ü§ñ</div><div class=\"agent-bubble\"><p>Pouria Rouzrokh is a radiologist.<br />\n",
              "<strong>Background Information:</strong><br />\n",
              "*   <strong>Full Name and Credentials:</strong> Pouria Rouzrokh, MD, MPH, MHPE.<br />\n",
              "*   <strong>Current Position and Institution:</strong> Dr. Rouzrokh is currently a Diagnostic Radiology Resident at Yale University School of Medicine, a position he will hold from 2025 to 2030. He also serves as an Adjunct Assistant Professor of Radiology at Mayo Clinic. Beyond his clinical and academic roles, he is recognized as an AI Researcher &amp; Developer.<br />\n",
              "*   <strong>Education and Training:</strong><br />\n",
              "*   <strong>Diagnostic Radiology Residency:</strong> Yale University School of Medicine, New Haven, CT, USA (2025-2030).<br />\n",
              "*   <strong>Internal Medicine Internship:</strong> Griffin Hospital, Derby, CT, USA (2024-2025).<br />\n",
              "*   <strong>Postdoctoral Research Fellowship:</strong> Mayo Clinic, Rochester, MN, USA (2020-2024), where his research focused on artificial intelligence, machine learning, and radiology.<br />\n",
              "*   <strong>Doctor of Medicine (MD):</strong> Tehran University of Medical Sciences, Tehran, Iran (2009-2018).<br />\n",
              "*   <strong>Master of Health Professions' Education (MHPE):</strong> Tehran University of Medical Sciences, Tehran, Iran (2011-2014).<br />\n",
              "*   <strong>Master of Public Health (MPH):</strong> Tehran University of Medical Sciences, Tehran, Iran (2012-2016).<br />\n",
              "*   <strong>Research Interests and Specialties:</strong> Dr. Rouzrokh is a physician-scientist and developer whose work is concentrated on applying machine learning to address healthcare challenges. His research encompasses medical imaging, clinical data analysis, and predictive modeling, with a particular emphasis on developing AI tools for automating quantitative measurements in radiology. He has also explored the use of AI for curating large-scale datasets and establishing systematic imaging registries to facilitate structured and scalable research, with a specific focus on hip arthroplasty during his research fellowship.<br />\n",
              "*   <strong>Professional Achievements and Affiliations:</strong><br />\n",
              "*   Director of the Mayo Clinic AI Laboratory (2020-2024).<br />\n",
              "*   Member of the Society for Imaging Informatics in Medicine (SIIM) since 2020.<br />\n",
              "*   Serves as a reviewer for the <em>Radiology Journal</em> (2024-Present) and <em>Radiology: Artificial Intelligence Journal</em> (2023-Present).<br />\n",
              "*   Member of the Radiological Society of North America (RSNA) since 2020.<br />\n",
              "*   Former Editorial Board Member (Trainee Editorial Board, RG-Team) for <em>RadioGraphics Journal</em> (2023-2025).<br />\n",
              "*   Co-founder and Chief Education Officer of a startup dedicated to developing gamified medical and public health education products.<br />\n",
              "*   Co-founder, Researcher, and Developer of a research initiative aimed at developing and promoting AI tools for advancing radiology and medical imaging.<br />\n",
              "*   Recipient of the 2023 NAIRS Annual Research Award for his presentation on \"Employing Generative AI to Visualize Ideal Total Hip Arthroplasty and Conduct Patient Specific Surgical Templating on Plain Radiographs.\"<br />\n",
              "*   Maintains a Google Scholar profile showcasing numerous publications in radiology, generative AI, deep learning, and computer vision.<br />\n",
              "*   <strong>Contact Information and Professional Profiles:</strong><br />\n",
              "*   Website: PouriaRouzrokh.com<br />\n",
              "*   GitHub: PouriaRouzrokh<br />\n",
              "*   Mayo Clinic Email: rouzrokh.pouria@mayo.edu<br />\n",
              "*   Yale University Email: Verified email at yale.edu.<br />\n",
              "{\"most_recent_papers\": [], \"most_cited_papers\": []}<br />\n",
              "Here's a curated list of publicly available URLs about Pouria Rouzrokh, organized by category:</p>\n",
              "<h3>Personal Website</h3>\n",
              "<ul>\n",
              "<li><strong>category</strong>: Personal Website</li>\n",
              "<li><strong>url</strong>: <code>https://www.pouriarouzrokh.com</code></li>\n",
              "<li><strong>description</strong>: Official website of Pouria Rouzrokh, AI researcher, developer, and physician-scientist, showcasing his projects, research, and expertise in artificial intelligence and machine learning.</li>\n",
              "<li><strong>platform</strong>: PouriaRouzrokh.com</li>\n",
              "</ul>\n",
              "<h3>Institutional Profiles</h3>\n",
              "<ul>\n",
              "<li><strong>category</strong>: Institutional</li>\n",
              "<li><strong>url</strong>: <code>https://medicine.yale.edu/profile/pouria-rouzrokh/</code></li>\n",
              "<li><strong>description</strong>: Diagnostic Radiology resident profile at Yale University School of Medicine, detailing his clinical practice and research at the intersection of medicine and technology.</li>\n",
              "<li><strong>platform</strong>: Yale School of Medicine</li>\n",
              "<li><strong>category</strong>: Institutional</li>\n",
              "<li><strong>url</strong>: <code>https://www.mayo.edu/research/labs/radiology-informatics/faculty-staff</code></li>\n",
              "<li><strong>description</strong>: Listing as an Assistant Professor of Radiology within the Radiology Informatics faculty and staff at Mayo Clinic Research.</li>\n",
              "<li><strong>platform</strong>: Mayo Clinic</li>\n",
              "</ul>\n",
              "<h3>Social Media &amp; Professional Networks</h3>\n",
              "<ul>\n",
              "<li><strong>category</strong>: Social Media</li>\n",
              "<li><strong>url</strong>: <code>https://github.com/PouriaRouzrokh</code></li>\n",
              "<li><strong>description</strong>: GitHub profile showcasing his repositories, projects, and contributions as a Physician &amp; AI Developer.</li>\n",
              "<li><strong>platform</strong>: GitHub</li>\n",
              "<li><strong>category</strong>: Social Media</li>\n",
              "<li><strong>url</strong>: <code>https://www.linkedin.com/in/pouria-rouzrokh</code></li>\n",
              "<li><strong>description</strong>: LinkedIn profile for Pouria Rouzrokh, detailing his professional experience, education, and skills.</li>\n",
              "<li><strong>platform</strong>: LinkedIn</li>\n",
              "<li><strong>category</strong>: Social Media</li>\n",
              "<li><strong>url</strong>: <code>https://x.com/PRouzrokh</code></li>\n",
              "<li><strong>description</strong>: Twitter/X profile for Pouria Rouzrokh.</li>\n",
              "<li><strong>platform</strong>: X (Twitter)</li>\n",
              "</ul>\n",
              "<h3>Research &amp; Academic Profiles</h3>\n",
              "<ul>\n",
              "<li><strong>category</strong>: Research Profile</li>\n",
              "<li><strong>url</strong>: <code>https://scholar.google.com/citations?user=r9a1fR8AAAAJ</code></li>\n",
              "<li><strong>description</strong>: Google Scholar profile listing his academic publications, citations, h-index, and research interests in radiology, generative AI, deep learning, and computer vision.</li>\n",
              "<li><strong>platform</strong>: Google Scholar</li>\n",
              "<li><strong>category</strong>: Research Profile</li>\n",
              "<li><strong>url</strong>: <code>https://www.researchgate.net/profile/Pouria-Rouzrokh</code></li>\n",
              "<li><strong>description</strong>: ResearchGate profile, showing his publications and academic activities.</li>\n",
              "<li><strong>platform</strong>: ResearchGate</li>\n",
              "<li><strong>category</strong>: Professional Profile</li>\n",
              "<li><strong>url</strong>: <code>https://radiology.rsna.org/search?q=Pouria%20Rouzrokh</code></li>\n",
              "<li><strong>description</strong>: Search results on RSNA Journals, featuring articles and special reports co-authored by Pouria Rouzrokh.</li>\n",
              "<li><strong>platform</strong>: RSNA Journals</li>\n",
              "</ul>\n",
              "<h3>Projects &amp; Initiatives</h3>\n",
              "<ul>\n",
              "<li><strong>category</strong>: Project Website</li>\n",
              "<li><strong>url</strong>: <code>https://lattelab.io/LatteReview/</code></li>\n",
              "<li><strong>description</strong>: Website for LatteReview, a Python framework for multi-agent review workflows using large language models, co-authored by Pouria Rouzrokh.</li>\n",
              "<li><strong>platform</strong>: LatteReview<br />\n",
              "{<br />\n",
              "\"person_name\": \"Pouria Rouzrokh\",<br />\n",
              "\"background\": \"Pouria Rouzrokh, MD, MPH, MHPE, is a Diagnostic Radiology Resident at Yale University School of Medicine (2025-2030) and an Adjunct Assistant Professor of Radiology at Mayo Clinic. He is also recognized as an AI Researcher &amp; Developer. His education includes a Diagnostic Radiology Residency at Yale, an Internal Medicine Internship at Griffin Hospital (2024-2025), and a Postdoctoral Research Fellowship at Mayo Clinic (2020-2024) with a focus on artificial intelligence, machine learning, and radiology. He holds an MD from Tehran University of Medical Sciences (2009-2018), an MHPE (2011-2014), and an MPH (2012-2016) from the same institution. Dr. Rouzrokh is a physician-scientist and developer specializing in applying machine learning to healthcare challenges, including medical imaging, clinical data analysis, and predictive modeling, with a particular emphasis on AI tools for automating quantitative measurements in radiology and curating large-scale datasets for imaging registries. He directed the Mayo Clinic AI Laboratory (2020-2024) and is a member of the Society for Imaging Informatics in Medicine (SIIM) and the Radiological Society of North America (RSNA) since 2020. He serves as a reviewer for the Radiology Journal (2024-Present) and Radiology: Artificial Intelligence Journal (2023-Present), and was a former Editorial Board Member (Trainee Editorial Board, RG-Team) for RadioGraphics Journal (2023-2025). He is also a co-founder and Chief Education Officer of a startup dedicated to developing gamified medical and public health education products, and a co-founder, researcher, and developer of a research initiative aimed at developing and promoting AI tools for advancing radiology and medical imaging. In 2023, he received the NAIRS Annual Research Award for his presentation on \\\"Employing Generative AI to Visualize Ideal Total Hip Arthroplasty and Conduct Patient Specific Surgical Templating on Plain Radiographs.\\\"\",<br />\n",
              "\"online_presence\": [<br />\n",
              "{<br />\n",
              "\"category\": \"Personal Website\",<br />\n",
              "\"url\": \"https://www.pouriarouzrokh.com\",<br />\n",
              "\"description\": \"Official website of Pouria Rouzrokh, AI researcher, developer, and physician-scientist, showcasing his projects, research, and expertise in artificial intelligence and machine learning.\",<br />\n",
              "\"platform\": \"PouriaRouzrokh.com\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Institutional\",<br />\n",
              "\"url\": \"https://medicine.yale.edu/profile/pouria-rouzrokh/\",<br />\n",
              "\"description\": \"Diagnostic Radiology resident profile at Yale University School of Medicine, detailing his clinical practice and research at the intersection of medicine and technology.\",<br />\n",
              "\"platform\": \"Yale School of Medicine\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Institutional\",<br />\n",
              "\"url\": \"https://www.mayo.edu/research/labs/radiology-informatics/faculty-staff\",<br />\n",
              "\"description\": \"Listing as an Assistant Professor of Radiology within the Radiology Informatics faculty and staff at Mayo Clinic Research.\",<br />\n",
              "\"platform\": \"Mayo Clinic\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Social Media\",<br />\n",
              "\"url\": \"https://github.com/PouriaRouzrokh\",<br />\n",
              "\"description\": \"GitHub profile showcasing his repositories, projects, and contributions as a Physician &amp; AI Developer.\",<br />\n",
              "\"platform\": \"GitHub\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Social Media\",<br />\n",
              "\"url\": \"https://www.linkedin.com/in/pouria-rouzrokh\",<br />\n",
              "\"description\": \"LinkedIn profile for Pouria Rouzrokh, detailing his professional experience, education, and skills.\",<br />\n",
              "\"platform\": \"LinkedIn\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Social Media\",<br />\n",
              "\"url\": \"https://x.com/PRouzrokh\",<br />\n",
              "\"description\": \"Twitter/X profile for Pouria Rouzrokh.\",<br />\n",
              "\"platform\": \"X (Twitter)\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Research Profile\",<br />\n",
              "\"url\": \"https://scholar.google.com/citations?user=r9a1fR8AAAAJ\",<br />\n",
              "\"description\": \"Google Scholar profile listing his academic publications, citations, h-index, and research interests in radiology, generative AI, deep learning, and computer vision.\",<br />\n",
              "\"platform\": \"Google Scholar\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Research Profile\",<br />\n",
              "\"url\": \"https://www.researchgate.net/profile/Pouria-Rouzrokh\",<br />\n",
              "\"description\": \"ResearchGate profile, showing his publications and academic activities.\",<br />\n",
              "\"platform\": \"ResearchGate\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Professional Profile\",<br />\n",
              "\"url\": \"https://radiology.rsna.org/search?q=Pouria%20Rouzrokh\",<br />\n",
              "\"description\": \"Search results on RSNA Journals, featuring articles and special reports co-authored by Pouria Rouzrokh.\",<br />\n",
              "\"platform\": \"RSNA Journals\"<br />\n",
              "},<br />\n",
              "{<br />\n",
              "\"category\": \"Project Website\",<br />\n",
              "\"url\": \"https://lattelab.io/LatteReview/\",<br />\n",
              "\"description\": \"Website for LatteReview, a Python framework for multi-agent review workflows using large language models, co-authored by Pouria Rouzrokh.\",<br />\n",
              "\"platform\": \"LatteReview\"<br />\n",
              "}<br />\n",
              "],<br />\n",
              "\"recent_publications\": {<br />\n",
              "\"most_recent_papers\": [],<br />\n",
              "\"most_cited_papers\": []<br />\n",
              "},<br />\n",
              "\"contact_information\": \"Mayo Clinic Email: rouzrokh.pouria@mayo.edu; Yale University Email: Verified email at yale.edu.\"<br />\n",
              "}</li>\n",
              "</ul></div></div><div class=\"user-row\"><div class=\"user-bubble\">exit</div><div class=\"avatar avatar-user\">üë§</div></div><div class=\"sys-log\">üî¥ Session ended.</div></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, that was a lot of work that these agents did for us, wasn't it?\n",
        "\n",
        "Well, we agree! Despite this impressive work, there are still a few points we need to discuss.\n",
        "\n",
        "---\n",
        "\n",
        "### The Nature of Multi-Agent Workflows\n",
        "\n",
        "Did you notice that in these past two agents (Parts 4 and 5), we actually spent **less time talking** with our agents and let our agents work more and more **on their own**?\n",
        "\n",
        "Well, that's what real multi-agent workflows look like! You **rarely use these multi-agent workflows for chatting**. Mostly, you let them go into the wilderness and do jobs for you that might not be easy for you to do‚Äîor at least would take a lot of your time.\n",
        "\n",
        "Even though multi-agent pipelines might still have some requirement to chat with the user, the chat assignment is often **delegated to a specific one of the many agents** that are present in the pipeline, and is mostly used for cases where the agent runs into any difficulty.\n",
        "\n",
        "**Key Takeaway:** We would like you to have this concept in mind‚Äîmost of our day-to-day interactions with agents are for conversations, but a **real agentic workflow is often focused on doing a real task**.\n",
        "\n",
        "---\n",
        "\n",
        "### JSON Output Instead of Markdown\n",
        "\n",
        "The other thing you might have noticed is that the output of the multi-agent pipeline above is **not the markdown file** that we wanted, but a **JSON file**. Well, why did this happen?\n",
        "\n",
        "This, to be honest with you, wasn't designed on purpose. Even though you could try to ask the formatter agent (which is the last agent in our pipeline) to give you back a markdown file and maybe save it to disk as the biography agent did, you might notice that this is **not a very reliable setup**.\n",
        "\n",
        "Because the pipeline has gotten too complicated now, chances are very high that the formatter agent might forget to call its tool or might not even return the markdown file at all. If you have doubts about it, go ahead and change the instructions for that agent!"
      ],
      "metadata": {
        "id": "hQfN5vvKfyim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "The above discussion brings up two more questions:\n",
        "\n",
        "### 1. How did the agent decide to give us a JSON file?\n",
        "\n",
        "If this agent was not tasked to bring markdown, then how did it decide to give us a JSON file?\n",
        "\n",
        "### 2. How can we get the markdown version?\n",
        "\n",
        "What can we do to get our hands on the markdown version of this information?\n",
        "\n",
        "---\n",
        "\n",
        "## Answer: Structured Outputs\n",
        "\n",
        "To answer the first question, we should tell you that another very useful feature of Google ADK agents is that you can **enforce them to follow a structured format for their outputs**.\n",
        "\n",
        "In almost all cases, a structured output is enforced using **JSON schemas** or **Pydantic classes**. In both cases, the output is going to be a JSON file.\n",
        "\n",
        "**Why JSON?**\n",
        "- JSON files are very frequently used in agents because they are the standard in web programming and JavaScript\n",
        "- They are the bread and butter of API building and passing data between different APIs\n",
        "- Developers love them for structured data exchange\n",
        "\n",
        "---\n",
        "\n",
        "## How We Enforced Structured Output\n",
        "\n",
        "Let's take a look at how we actually enforced the formatter agent to create this JSON for us:\n",
        "```python\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, List\n",
        "from google.adk.agents import LlmAgent\n",
        "\n",
        "# Define Pydantic models for structured output\n",
        "class Paper(BaseModel):\n",
        "    title: str\n",
        "    journal: str\n",
        "    year: int\n",
        "    url: str\n",
        "    citations: int\n",
        "    authors: str\n",
        "\n",
        "\n",
        "class PublicationSection(BaseModel):\n",
        "    most_recent_papers: List[Paper]\n",
        "    most_cited_papers: List[Paper]\n",
        "\n",
        "\n",
        "class URLInfo(BaseModel):\n",
        "    category: str\n",
        "    url: str\n",
        "    description: str\n",
        "    platform: str\n",
        "\n",
        "\n",
        "class NetworkingProfile(BaseModel):\n",
        "    person_name: str\n",
        "    background: str\n",
        "    online_presence: List[URLInfo]\n",
        "    recent_publications: PublicationSection\n",
        "    contact_information: Optional[str] = None\n",
        "\n",
        "\n",
        "# Define the formatter agent - Step 3: Compile everything into structured output\n",
        "formatter_agent = LlmAgent(\n",
        "    name=\"profile_formatter_agent\",\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    output_schema=NetworkingProfile,  # ‚Üê This enforces the structured output!\n",
        "    instruction=(\n",
        "        \"You are a profile formatting agent. Your role is to compile all gathered information \"\n",
        "        \"into a structured networking profile.\\n\\n\"\n",
        "        \n",
        "        \"When given information from previous agents:\\n\"\n",
        "        \"1. Review all information provided:\\n\"\n",
        "        \"   - Background information from verification agent\\n\"\n",
        "        \"   - URLs from URL finder agent (social media, personal web pages, etc.)\\n\"\n",
        "        \"   - Recent articles from article agent (including Most Recent Papers and Most Cited Papers sections)\\n\\n\"\n",
        "        \"2. Extract and structure the information according to the required format:\\n\"\n",
        "        \"   - person_name: The full name of the person\\n\"\n",
        "        \"   - background: Background information from verification agent (clear, professional format)\\n\"\n",
        "        \"   - online_presence: List of URLInfo objects with:\\n\"\n",
        "        \"     * category: Type (e.g., \\\"Social Media\\\", \\\"Personal Website\\\", \\\"Institutional\\\")\\n\"\n",
        "        \"     * url: The direct URL\\n\"\n",
        "        \"     * description: Brief description of the page\\n\"\n",
        "        \"     * platform: Platform or website name (e.g., \\\"LinkedIn\\\", \\\"Twitter\\\", institution name)\\n\"\n",
        "        \"   - recent_publications: PublicationSection with:\\n\"\n",
        "        \"     * most_recent_papers: List of Paper objects (up to 10)\\n\"\n",
        "        \"     * most_cited_papers: List of Paper objects (up to 10)\\n\"\n",
        "        \"     Each Paper should have: title, journal, year (integer), url, citations (integer), authors\\n\"\n",
        "        \"   - contact_information: Contact info if available from background research (optional)\\n\\n\"\n",
        "        \"3. Structure the response according to the NetworkingProfile schema.\\n\"\n",
        "        \"4. Ensure all data is accurate and well-organized.\\n\"\n",
        "        \"5. Return the structured profile - this will be returned to the user.\\n\\n\"\n",
        "        \"IMPORTANT: Return the structured profile according to the NetworkingProfile schema. \"\n",
        "        \"Do NOT save any files - just return the structured data.\"\n",
        "    ),\n",
        "    description=(\n",
        "        \"Compiles all gathered information (background, URLs, articles) into a \"\n",
        "        \"structured networking profile using Pydantic models.\"\n",
        "    ),\n",
        "    tools=[],\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "**The key line:** `output_schema=NetworkingProfile`\n",
        "\n",
        "This parameter tells the agent that its output **must** conform to the `NetworkingProfile` Pydantic model. The agent will automatically structure its response as a JSON object matching this schema, ensuring consistency and making the data easy to work with programmatically."
      ],
      "metadata": {
        "id": "lRF710dif_f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Issue 2: Converting JSON to Markdown: A Better Approach\n",
        "\n",
        "Alright, now let's go back to our second question: **How can we convert this JSON output to a markdown format?**\n",
        "\n",
        "---\n",
        "\n",
        "### The Problem with Terminal-Based Interactions\n",
        "\n",
        "Well, in real-life programming, you cannot rely on interacting with your agents in a terminal. Even though we created a beautiful UI to avoid seeing those ugly terminal interactions, this still has a lot of drawbacks.\n",
        "\n",
        "Most important of which is that if we do not rely on saving files to disk, we have **no way of getting the output of our agents** unless by running some very ugly bash commands.\n",
        "\n",
        "We are sure you agree that this is not an easy way to interact with the outputs of our agents in our notebook environment.\n",
        "\n",
        "---\n",
        "\n",
        "## Time to Go Deeper: Running Agents Programmatically\n",
        "\n",
        "So it's finally time to learn **how to run an agent or a multi-agent pipeline from within our code** without relying on the Google ADK run commands.\n",
        "\n",
        "In fact, it's time to learn that the `adk run` command is just a **wrapper** around maybe a handful of lines of code that we can write ourselves‚Äîand then get **full control** over our agent pipeline.\n",
        "\n",
        "To do this, we need to familiarize ourselves with three key concepts:\n",
        "\n",
        "### Application (App)\n",
        "\n",
        "**App** is the name of the application that we are creating. Google ADK sometimes imposes limitations on the name of the apps, but for now, let's imagine that you can name your application whatever you like.\n",
        "\n",
        "### Session\n",
        "\n",
        "**Session** is basically a separate instance of conversation or activity that you assign to your agent pipeline. Each user interacting with the agent pipeline will have their own session, and the sessions are separated and fully independent from each other.\n",
        "\n",
        "Think of the session as a **context** that you can engineer for the agent and fill it with data, information, and insights that will help your agents work as expected. You might have heard about things like **memory** that agents could have and can rely on for remembering things‚Äîwell, these are things that someone can save on an agent pipeline session and are immediately accessible to agents.\n",
        "\n",
        "Regardless, let's put aside the deeper aspects of sessions as they go a little bit beyond the scope of our today's workshop.\n",
        "\n",
        "### Session Service\n",
        "\n",
        "**SessionService** is responsible for managing conversation history and state for different users and sessions. It keeps track of the messages exchanged.\n",
        "\n",
        "As we were talking about sessions, those of you who might have more experience with coding could have imagined: **where does all this information get stored?** Do we store this in memory or can we store them in databases?\n",
        "\n",
        "Well, the answer is yes to both! The default behavior of Google ADK is to save the sessions in **the system's memory** using `InMemorySessionService`, which is suitable for testing and simple applications. But you can also configure it to save sessions in **SQLite databases**, which is great for production. Even more interesting, you can save everything on **Google Cloud services**, which offer specific types of databases for enterprise-scale deployments.\n",
        "\n",
        "### Runner\n",
        "\n",
        "**Runner** is the main engine to run your entire pipeline and all the sessions at the same time. It orchestrates the interaction flow‚Äîit takes user input, routes it to the appropriate agent, manages calls to the LLM and tools based on the agent's logic, handles session updates via the SessionService, and yields events representing the progress of the interaction. The runner keeps track of all the sessions and ensures the multi-agent pipeline can adequately reply and respond to all the requests it is getting from different sessions.\n",
        "\n",
        "---\n",
        "\n",
        "## Running Our Networking Agent Programmatically\n",
        "\n",
        "For now, we are going to define a **runner and session** for our networking agent and see how we can get the output of the multi-agent pipeline and save it as markdown.\n",
        "\n",
        "Note that previously the `adk run` command was handling all the outputs from the agents for us and could simply pass the ultimate response of the agent pipeline back to be seen by us. But when we are dealing with the runner and sessions ourselves, we should also be **responsible for parsing the outputs** of the agents and figuring out which responses are intermediate and which responses are final.\n",
        "\n",
        "This is exactly what we will do in the next couple of cells. Let's go through all these codes and see if you can follow them."
      ],
      "metadata": {
        "id": "wT1Te3xcgSvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Runner Implementation for Networking Agent\n",
        "# This demonstrates how to build custom runners and sessions\n",
        "# Note: In Colab, you'll need to upload the scripts directory first\n",
        "\n",
        "import json\n",
        "import uuid\n",
        "import asyncio\n",
        "from pathlib import Path\n",
        "\n",
        "# Import the networking agent and its components\n",
        "from agents.part5.networking_agent.agent import root_agent\n",
        "from agents.part5.networking_agent.sub_agents.formatter_agent import NetworkingProfile\n",
        "from google.adk import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import types\n",
        "\n",
        "# Run this in a Colab cell\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "QT0yhKmsa5ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title A utility tool that will help us convert the JSON output to a Markdown file.\n",
        "\n",
        "def profile_to_markdown(profile: NetworkingProfile) -> str:\n",
        "    \"\"\"Convert NetworkingProfile Pydantic model to markdown format.\"\"\"\n",
        "    markdown_parts = []\n",
        "\n",
        "    # Header\n",
        "    markdown_parts.append(f\"# {profile.person_name} - Networking Profile\\n\")\n",
        "\n",
        "    # Background\n",
        "    markdown_parts.append(\"## Background\\n\")\n",
        "    markdown_parts.append(f\"{profile.background}\\n\")\n",
        "\n",
        "    # Online Presence\n",
        "    markdown_parts.append(\"## Online Presence\\n\")\n",
        "    if profile.online_presence:\n",
        "        # Group URLs by category\n",
        "        categories = {}\n",
        "        for url_info in profile.online_presence:\n",
        "            category = url_info.category\n",
        "            if category not in categories:\n",
        "                categories[category] = []\n",
        "            categories[category].append(url_info)\n",
        "\n",
        "        # Write each category\n",
        "        for category, urls in categories.items():\n",
        "            markdown_parts.append(f\"### {category}\\n\")\n",
        "            for url_info in urls:\n",
        "                markdown_parts.append(f\"- [{url_info.platform}]({url_info.url}) - {url_info.description}\\n\")\n",
        "    else:\n",
        "        markdown_parts.append(\"No online presence information available.\\n\")\n",
        "    markdown_parts.append(\"\")\n",
        "\n",
        "    # Recent Publications\n",
        "    markdown_parts.append(\"## Recent Publications\\n\")\n",
        "\n",
        "    # Most Recent Papers\n",
        "    if profile.recent_publications.most_recent_papers:\n",
        "        markdown_parts.append(\"### Most Recent Papers\\n\")\n",
        "        for paper in profile.recent_publications.most_recent_papers:\n",
        "            markdown_parts.append(\n",
        "                f\"- **{paper.title}** - *{paper.journal}* ({paper.year}) \"\n",
        "                f\"[Link]({paper.url}) - Citations: {paper.citations}\\n\"\n",
        "            )\n",
        "        markdown_parts.append(\"\")\n",
        "\n",
        "    # Most Cited Papers\n",
        "    if profile.recent_publications.most_cited_papers:\n",
        "        markdown_parts.append(\"### Most Cited Papers\\n\")\n",
        "        for paper in profile.recent_publications.most_cited_papers:\n",
        "            markdown_parts.append(\n",
        "                f\"- **{paper.title}** - *{paper.journal}* ({paper.year}) \"\n",
        "                f\"[Link]({paper.url}) - Citations: {paper.citations}\\n\"\n",
        "            )\n",
        "        markdown_parts.append(\"\")\n",
        "\n",
        "    # Contact Information\n",
        "    if profile.contact_information:\n",
        "        markdown_parts.append(\"## Contact Information\\n\")\n",
        "        markdown_parts.append(f\"{profile.contact_information}\\n\")\n",
        "\n",
        "    return \"\".join(markdown_parts)"
      ],
      "metadata": {
        "id": "y-DwcLkxhLEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main function for creating runner, session, and executing the agents.\n",
        "\n",
        "async def run_agent_async(person_name: str) -> NetworkingProfile:\n",
        "    \"\"\"Run the networking agent with a given person's name (async version).\"\"\"\n",
        "    # Create session service\n",
        "    session_service = InMemorySessionService()\n",
        "\n",
        "    # Create a unique session ID\n",
        "    session_id = str(uuid.uuid4())\n",
        "    user_id = \"user\"\n",
        "    app_name = \"agents\"\n",
        "\n",
        "    # Create the session explicitly before running (as per ADK documentation)\n",
        "    _ = await session_service.create_session(\n",
        "        app_name=app_name,\n",
        "        user_id=user_id,\n",
        "        session_id=session_id\n",
        "    )\n",
        "\n",
        "    # Create runner with the root agent\n",
        "    runner = Runner(\n",
        "        agent=root_agent,\n",
        "        app_name=app_name,\n",
        "        session_service=session_service\n",
        "    )\n",
        "\n",
        "    # Create the message content\n",
        "    message = types.Content(\n",
        "        parts=[types.Part(text=f\"Create a networking profile for {person_name}\")],\n",
        "        role=\"user\"\n",
        "    )\n",
        "\n",
        "    # Run the agent and collect events using run_async\n",
        "    events = []\n",
        "    final_response_text = None\n",
        "\n",
        "    try:\n",
        "        async for event in runner.run_async(\n",
        "            user_id=user_id,\n",
        "            session_id=session_id,\n",
        "            new_message=message\n",
        "        ):\n",
        "            events.append(event)\n",
        "\n",
        "            # Check if this is the final response (as per ADK documentation)\n",
        "            if hasattr(event, 'is_final_response') and event.is_final_response():\n",
        "                if hasattr(event, 'content') and event.content:\n",
        "                    if hasattr(event.content, 'parts') and event.content.parts:\n",
        "                        for part in event.content.parts:\n",
        "                            if hasattr(part, 'text') and part.text:\n",
        "                                final_response_text = part.text\n",
        "                                # Try to parse as JSON (structured output)\n",
        "                                try:\n",
        "                                    data = json.loads(part.text)\n",
        "                                    if isinstance(data, dict) and 'person_name' in data:\n",
        "                                        return NetworkingProfile(**data)\n",
        "                                except (json.JSONDecodeError, TypeError, ValueError):\n",
        "                                    pass\n",
        "\n",
        "            # Also check event.content for structured output\n",
        "            if hasattr(event, 'content') and event.content:\n",
        "                if hasattr(event.content, 'parts') and event.content.parts:\n",
        "                    for part in event.content.parts:\n",
        "                        if hasattr(part, 'text') and part.text:\n",
        "                            # Try to parse as JSON (structured output)\n",
        "                            try:\n",
        "                                data = json.loads(part.text)\n",
        "                                if isinstance(data, dict) and 'person_name' in data:\n",
        "                                    return NetworkingProfile(**data)\n",
        "                            except (json.JSONDecodeError, TypeError, ValueError):\n",
        "                                pass\n",
        "    except Exception as e:\n",
        "        print(f\"Error during event processing: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # If we have a final response text but couldn't parse it, try one more time\n",
        "    if final_response_text:\n",
        "        try:\n",
        "            data = json.loads(final_response_text)\n",
        "            if isinstance(data, dict) and 'person_name' in data:\n",
        "                return NetworkingProfile(**data)\n",
        "        except (json.JSONDecodeError, TypeError, ValueError):\n",
        "            pass\n",
        "\n",
        "    # Debug: Print event types to help diagnose\n",
        "    if events:\n",
        "        print(f\"Debug: Received {len(events)} events\")\n",
        "        print(f\"Debug: Event types: {[type(e).__name__ for e in events[-5:]]}\")\n",
        "        if final_response_text:\n",
        "            print(f\"Debug: Final response text (first 500 chars): {final_response_text[:500]}\")\n",
        "\n",
        "    raise ValueError(f\"Could not parse NetworkingProfile from agent response. \"\n",
        "                    f\"Received {len(events)} events.\")\n"
      ],
      "metadata": {
        "id": "s8Pli80liLN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_name = \"Pouria Rouzrokh\"  # Change this to any radiologist's name\n",
        "\n",
        "print(f\"Researching networking profile for: {person_name}\")\n",
        "print(\"This may take a few moments...\\n\")\n",
        "\n",
        "try:\n",
        "    # Run the agent\n",
        "    profile = asyncio.run(run_agent_async(person_name))\n",
        "\n",
        "    # Convert to markdown\n",
        "    markdown_content = profile_to_markdown(profile)\n",
        "\n",
        "    # Display the markdown (in Colab, this will render nicely)\n",
        "    from IPython.display import Markdown, display\n",
        "    display(Markdown(markdown_content))\n",
        "\n",
        "    # Optionally save to file\n",
        "    # output_path = Path(\"/content\") / f\"{person_name.replace(' ', '_').lower()}_profile.md\"\n",
        "    # with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    #     f.write(markdown_content)\n",
        "    # print(f\"\\n‚úì Profile saved to: {output_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úó Error running agent: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cMNA5Hjqimge",
        "outputId": "b9a1416b-85be-4cde-a545-69d27feeb626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Researching networking profile for: Pouria Rouzrokh\n",
            "This may take a few moments...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
            "ERROR:asyncio:Unclosed connector\n",
            "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7b33099af7d0>, 584.051249309)])']\n",
            "connector: <aiohttp.connector.TCPConnector object at 0x7b330982b080>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Pouria Rouzrokh - Networking Profile\n## Background\nPouria Rouzrokh, MD, MPH, MHPE, is a Diagnostic Radiology Resident at Yale University, where he engages in both clinical practice and research focusing on the intersection of medicine and technology. He also holds an Adjunct Assistant Professorship in Radiology at Mayo Clinic. Education and Training: Doctor of Medicine (MD): Tehran University of Medical Sciences, Tehran, Iran (2009-2018). His dissertation focused on developing, implementing, and evaluating a curriculum for teaching medical students and residents communication skills in difficult situations. Master of Public Health (MPH): Tehran University of Medical Sciences, Tehran, Iran (2012-2016). His dissertation focused on a gamified curriculum for teaching medical students about social determinants of health. Master of Health Professions' Education (MHPE): Tehran University of Medical Sciences, Tehran, Iran (2011-2014). Postdoctoral Research Fellowship: Mayo Clinic, Rochester, MN, USA (2020-2024), with research areas in artificial intelligence, machine learning, and radiology. Internal Medicine Internship: Griffin Hospital, Derby, CT, USA (2024-2025). Diagnostic Radiology Residency: Yale University School of Medicine, New Haven, CT, USA (2025-2030). Research Interests and Specialties: Dr. Rouzrokh is a physician-scientist and developer specializing in the application of artificial intelligence (AI) and machine learning (ML) in healthcare, particularly in medical imaging. His work involves developing AI tools for automating quantitative measurements in radiology, curating large-scale datasets, building systematic imaging registries, and optimizing clinical workflows. He is also passionate about the explainability and fairness of AI models, having investigated algorithmic bias in medical AI. His contributions span musculoskeletal imaging, neuroimaging, and general clinical data science. He is involved in research initiatives focused on developing and promoting AI tools for advancing radiology and medical imaging, and has experience as a data scientist for orthopedic surgery AI tools. Professional Achievements and Activities: Recipient of the 2023 NAIRS Annual Research Award. Member of the Radiological Society of North America (RSNA) (2020 - Present). Member of the Society for Imaging Informatics in Medicine (SIIM) (2020 - Present). Reviewer for Radiology Journal (2024 - Present) and Radiology: Artificial Intelligence Journal (2023 - Present). Editorial Board Member for RadioGraphics Journal (Trainee Editorial Board - RG-Team) (2023 - 2025). Co-founder of Vision Research Lab, a research initiative for AI tools in radiology. Authored numerous publications on AI in radiology and medical imaging. Recognized with honors such as the University Chancellor Award (Tehran University of Medical Sciences, 2018), Runner-Up Award for Innovation in Medical Education (Ministry of Health, Iran, 2018), Third Place National Award for Innovation in Medical Education (Ministry of Health, Iran, 2017), and a Gold Medal in the National Medical Student Olympiad (Ministry of Health, Iran, 2015).\n## Online Presence\n### Personal Website\n- [PouriaRouzrokh.com](https://www.pouriarouzrokh.com) - Official website showcasing his work as an AI researcher, developer, and physician-scientist, including his education, research, and professional activities.\n### Institutional Profile\n- [Yale University School of Medicine](https://medicine.yale.edu/profile/pouria-rouzrokh/) - Profile page on the Yale School of Medicine website, detailing his diagnostic radiology residency, research interests, and biography.\n- [Mayo Clinic](https://www.mayoclinic.org/research/labs/radiology-informatics-bradley-j-erickson/faculty-staff) - Listing as an Assistant Professor of Radiology within the Radiology Informatics lab at Mayo Clinic Research.\n- [Griffin Hospital](https://meded.griffinhealth.org/residents) - Listing on the Griffin Hospital medical education residents page, showing his PGY-2 status.\n### Social Media\n- [LinkedIn](https://www.linkedin.com/in/pouria-rouzrokh) - Professional networking profile on LinkedIn.\n- [X (formerly Twitter)](https://x.com/PRouzrokh) - Microblogging and social networking profile on X (formerly Twitter).\n### Research Profile\n- [Google Scholar](https://scholar.google.com/citations?user=yWv1N-wAAAAJ&hl=en) - Google Scholar profile listing his academic publications, citations, and h-index.\n- [ResearchGate](https://www.researchgate.net/profile/Pouria-Rouzrokh) - ResearchGate profile for academic networking and sharing research, including publications and collaborations.\n### Developer Profile\n- [GitHub](https://github.com/PouriaRouzrokh) - GitHub profile showcasing his projects and code repositories as a physician and AI developer.\n### Professional Publication\n- [RSNA Journals](https://pubs.rsna.org/doi/full/10.1148/ryai.220059) - An article titled 'Mitigating Bias in Radiology Machine Learning: 1. Data Handling' authored by Pouria Rouzrokh on RSNA's Radiology: Artificial Intelligence journal.\n## Recent Publications\n### Most Recent Papers\n- **A Current Review of Generative AI in Medicine: Core Concepts, Applications, and Current Limitations** - *Current Reviews in Musculoskeletal Medicine* (2025) [Link](https://www.semanticscholar.org/paper/5b373d8565443bcb806fe2ed6cd7185d45c2bca2) - Citations: 7\n- **Challenges of Gingival Surgery Approaches in the Treatment of Peri-Implantitis: A Systematic Review** - *Journal of Pharmacy and Bioallied Sciences* (2025) [Link](https://www.semanticscholar.org/paper/27018b14939b91ca0e263b7f66a694be854ca2dd) - Citations: 0\n- **LatteReview: A Multi-Agent Framework for Systematic Review Automation Using Large Language Models** - *arXiv.org* (2025) [Link](https://www.semanticscholar.org/paper/d0e126289ff34c517668da35a9a205012dd8bdec) - Citations: 0\n- **Applying for an American radiology residency as an international medical graduate: The NRMP match.** - *Current problems in diagnostic radiology* (2025) [Link](https://www.semanticscholar.org/paper/9350ba6502fa73c6866ad044f3e701cde02c2961) - Citations: 0\n- **Winning at the Radiology Podium: First-timer's Guide to Crafting and Delivering a Memorable Conference Presentation.** - *Radiographics* (2025) [Link](https://www.semanticscholar.org/paper/05557d6b1851f113192ff7094a493e51c1d7a02e) - Citations: 0\n- **Bone Appetit: Skellytour Sets the Table for Robust Skeletal Segmentation.** - *Radiology: Artificial Intelligence* (2025) [Link](https://www.semanticscholar.org/paper/369ced05ec8782d9224e4687d3753b1ba93cce78) - Citations: 0\n- **The Path to Becoming a Peer Reviewer for Radiology Journals: Recipe for Trainees.** - *Radiographics* (2025) [Link](https://www.semanticscholar.org/paper/3e9ca1d583080caaf68bc075ec78864f98c77846) - Citations: 0\n- **Diagnostic performance of X-ray-based deep learning models for detecting ankle and foot fractures: a systematic review and meta-analysis.** - *Skeletal Radiology* (2025) [Link](https://www.semanticscholar.org/paper/5eebeaebbbee374978972fcc9c72b48f6441719d) - Citations: 0\n- **Explaining explainability: The role of XAI in medical imaging.** - *European Journal of Radiology* (2024) [Link](https://www.semanticscholar.org/paper/68adc9f9b87fb0b9100d5698505b6b58f268e074) - Citations: 9\n- **CONFLARE: CONFormal LArge language model REtrieval** - *arXiv.org* (2024) [Link](https://www.semanticscholar.org/paper/02b1b4594a79dafe57ac3411cda5e83c35e22b91) - Citations: 4\n### Most Cited Papers\n- **Mitigating Bias in Radiology Machine Learning: 1. Data Handling.** - *Radiology: Artificial Intelligence* (2022) [Link](https://www.semanticscholar.org/paper/caaf3277faea39df66b92d950b3a5b406f1d2310) - Citations: 101\n- **THA-AID: Deep Learning Tool for Total Hip Arthroplasty Automatic Implant Detection with Uncertainty and Outlier Quantification.** - *Journal of Arthroplasty* (2023) [Link](https://www.semanticscholar.org/paper/73de9eba5ba25581ad8666147a86a4bc2ec4baf4) - Citations: 20\n- **Deep Learning Dramatically Reduces the Work Associated with Image Cataloguing and Analysis: Commentary on an article by Pouria Rouzrokh, MD, MPH, MHPE, et al.: \"Applying Deep Learning to Establish a Total Hip Arthroplasty Radiography Registry. A Stepwise Approach\".** - *Journal of Bone and Joint Surgery. American volume* (2022) [Link](https://www.semanticscholar.org/paper/78203686aacd193766a4229598f4f9c2e5b78554) - Citations: 9\n- **Explaining explainability: The role of XAI in medical imaging.** - *European Journal of Radiology* (2024) [Link](https://www.semanticscholar.org/paper/68adc9f9b87fb0b9100d5698505b6b58f268e074) - Citations: 9\n- **A Current Review of Generative AI in Medicine: Core Concepts, Applications, and Current Limitations** - *Current Reviews in Musculoskeletal Medicine* (2025) [Link](https://www.semanticscholar.org/paper/5b373d8565443bcb806fe2ed6cd7185d45c2bca2) - Citations: 7\n- **CONFLARE: CONFormal LArge language model REtrieval** - *arXiv.org* (2024) [Link](https://www.semanticscholar.org/paper/02b1b4594a79dafe57ac3411cda5e83c35e22b91) - Citations: 4\n- **Preparing Radiologists for an Artificial Intelligence-enhanced Future: Tips for Trainees.** - *Radiographics* (2024) [Link](https://www.semanticscholar.org/paper/c73f29ad52cf271b46e4abf5eba63a40d0d177e1) - Citations: 3\n- **RadRotator: 3D Rotation of Radiographs with Diffusion Models** - *arXiv.org* (2024) [Link](https://www.semanticscholar.org/paper/212a1939b0b69c3ef3d55413da7bf369438337ee) - Citations: 2\n- **Ovarian Fibromatosis.** - *Radiographics* (2024) [Link](https://www.semanticscholar.org/paper/068233c9def01293c095ee4eee3925d0eb24dcec) - Citations: 1\n- **The Era of Artificial Intelligence in Radiology: How to Prepare for a Different Future.** - *Academic Radiology* (2024) [Link](https://www.semanticscholar.org/paper/c7598f5e66450b302cdfe7591aa20c71c2ea1c86) - Citations: 1\n## Contact Information\nrouzrokh.pouria@mayo.edu\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Words\n",
        "\n",
        "All right, now that you saw a very complicated multi-agent pipeline, we think it's time to adjourn this notebook. However, there is much, much more content to learn about agentic AI and the Google ADK framework that we couldn't cover today.\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Resources\n",
        "\n",
        "The following are a list of resources that you can visit yourself and learn more about:\n",
        "\n",
        "- **[Agent Development Kit Documentation](https://google.github.io/adk-docs/)**\n",
        "- **[ADK Masterclass](https://www.youtube.com/watch?v=P4VFL9nIaIA])**\n",
        "- **[ADK Tutorial Google Colab by Google](https://colab.research.google.com/github/google/adk-docs/blob/main/examples/python/tutorial/agent_team/adk_tutorial.ipynb)**\n",
        "\n",
        "---\n",
        "\n",
        "## Assignment: Part 6 - Radiology Guidelines Research Agent\n",
        "\n",
        "Also, it is worth mentioning that there is a **Part 6** to this notebook that we did not cover. It contains an entirely new multi-agent pipeline for researching radiology guidelines.\n",
        "\n",
        "We believe playing with this new agent framework and maybe trying to put it to work is a good assignment for you. We did not include the codes to run that part here, but it should not be that difficult for you to run the Part 6 multi-agent framework by looking at and reflecting on the content that we have covered so far.\n",
        "\n",
        "---\n",
        "\n",
        "At the very end, we would like to thank you for reading, listening, or watching us until the very end. We wish you can create multi-agent pipelines that achieve things that you yourself could never do alone.\n",
        "\n",
        "**Thank you!** üöÄ"
      ],
      "metadata": {
        "id": "KmR0dFl2mSJ1"
      }
    }
  ]
}