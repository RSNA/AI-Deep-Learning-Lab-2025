{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybylmep3wivS"
      },
      "source": [
        "~~~\n",
        "Copyright 2025 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssf4Y1uMv60A"
      },
      "source": [
        "# Using image embeddings to train a classification model\n",
        "\n",
        "In this notebook we will train a model to classify findings from chest x-ray images in the [NIH-14 dataset](https://nihcc.app.box.com/v/ChestXray-NIHCC) based on embeddings generated by the [MedSigLIP model](https://developers.google.com/health-ai-developer-foundations/medsiglip).\n",
        "\n",
        "NIH-14 contains chest x-ray images with labelled classes.\n",
        "\n",
        "The MedSigLIP model is used to generate rich embeddings for medical images allowing us to train a machine learning model with less data and compute compared to training from scratch. Visit the [MedSigLIP page](https://developers.google.com/health-ai-developer-foundations/medsiglip) on the HAI-DEF site to learn more about the model.\n",
        "\n",
        "We will frame this as a classification problem, where the model takes in a 6144 dimensional embedding and the label is X\n",
        "<table><tbody><tr>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/RSNA/AI-Deep-Learning-Lab-2025/blob/main/DL%20Lab%20-%20Leveraging%20pre-trained%20embeddings%20models%20for%20your%20use%20cases%20and%20your%20data/RSNA_Embeddings_Workshop.ipynb\">\n",
        "      <img alt=\"Google Colab logo\" src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" width=\"32px\"><br> Run in Google Colab\n",
        "    </a>\n",
        "  </td>\n",
        "</tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXZXH0rumwbG"
      },
      "source": [
        "## Setup\n",
        "\n",
        "To complete this tutorial, you'll need to have a runtime with [sufficient resources](https://ai.google.dev/gemma/docs/core#sizes) to run the MedGemma model.\n",
        "\n",
        "You can try out MedGemma 4B for free in Google Colab using a T4 GPU:\n",
        "\n",
        "1. In the upper-right of the Colab window, select **â–¾ (Additional connection options)**.\n",
        "2. Select **Change runtime type**.\n",
        "3. Under **Hardware accelerator**, select **T4 GPU**.\n",
        "\n",
        "**Note**: To run the demo with MedGemma 27B in Google Colab, you will need a runtime with an A100 GPU and use 4-bit quantization to reduce memory usage. The performance of quantized versions has not been evaluated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "dIXyJRBpr4jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHbC0-JAxlR2"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import io\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from google.cloud import storage\n",
        "import json\n",
        "from google.colab import output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from google.cloud import storage\n",
        "\n",
        "# Configuration\n",
        "gcs_path = \"gs://healthai-us/medsiglip/cxr-14-embeddings-with-labels.jsonl\"\n",
        "local_filename = \"cxr-14-embeddings-with-labels.jsonl\"\n",
        "\n",
        "# Parse GCS Path\n",
        "path_parts = gcs_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
        "bucket_name = path_parts[0]\n",
        "blob_name = path_parts[1]\n",
        "\n",
        "print(f\"Downloading from Bucket: {bucket_name}, Blob: {blob_name}\")\n",
        "\n",
        "# Initialize Client (Anonymous for public access)\n",
        "client = storage.Client.create_anonymous_client()\n",
        "bucket = client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "\n",
        "# Download to local file\n",
        "blob.download_to_filename(local_filename)\n",
        "print(f\"Downloaded to {local_filename}\")\n",
        "\n",
        "# Read the file\n",
        "data = []\n",
        "errors = 0\n",
        "\n",
        "with open(local_filename, 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if not line.strip():\n",
        "            continue\n",
        "        try:\n",
        "            data.append(json.loads(line))\n",
        "        except json.JSONDecodeError as e:\n",
        "            errors += 1\n",
        "            if errors <= 5:\n",
        "                print(f\"Skipping error on line {i+1}: {e}\")\n",
        "\n",
        "if errors > 5:\n",
        "    print(f\"... and {errors - 5} more errors.\")\n",
        "\n",
        "df_embeddings = pd.DataFrame(data)\n",
        "print(f\"Successfully loaded {len(df_embeddings)} rows (skipped {errors} invalid lines).\")\n",
        "display(df_embeddings.head())"
      ],
      "metadata": {
        "id": "4Db8rkhq3LKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the distribution of labels"
      ],
      "metadata": {
        "id": "pYTcFg_o1ekE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define metadata columns to exclude\n",
        "meta_cols = ['path', 'embedding', 'Patient ID', 'Patient Age', 'Patient Sex', 'Follow-up #', 'subject_id']\n",
        "\n",
        "# Identify label columns (all columns that are not metadata)\n",
        "label_cols = [c for c in df_embeddings.columns if c not in meta_cols]\n",
        "\n",
        "print(f\"Calculating counts for {len(label_cols)} labels...\")\n",
        "\n",
        "# Compute counts\n",
        "counts_data = []\n",
        "for col in label_cols:\n",
        "    # values are 0.0 or 1.0\n",
        "    positives = int(df_embeddings[col].sum())\n",
        "    negatives = len(df_embeddings) - positives\n",
        "    counts_data.append({\n",
        "        'Finding': col,\n",
        "        'Positives': positives,\n",
        "        'Negatives': negatives\n",
        "    })\n",
        "\n",
        "# Create DataFrame and sort\n",
        "counts_df_final = pd.DataFrame(counts_data)\n",
        "counts_df_final = counts_df_final.sort_values(by='Positives', ascending=False).reset_index(drop=True)\n",
        "\n",
        "display(counts_df_final)"
      ],
      "metadata": {
        "id": "tTUqAwIb9bmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "Hjy9v8pxLz0S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ce3e71"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# 1. Condition Dropdown\n",
        "conditions = counts_df_final['Finding'].tolist()\n",
        "\n",
        "initial_dropdown_value = conditions[5] # Default to the first condition\n",
        "\n",
        "# Check if 'selected_condition' variable exists in the global scope\n",
        "# and if its current value is a valid option in the 'conditions' list.\n",
        "if 'selected_condition' in globals() and globals()['selected_condition'] in conditions:\n",
        "    initial_dropdown_value = globals()['selected_condition']\n",
        "\n",
        "condition_dropdown = widgets.Dropdown(\n",
        "    options=conditions,\n",
        "    value=initial_dropdown_value,\n",
        "    description='Condition:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Output widget for displaying dynamic stats\n",
        "stats_output = widgets.Output()\n",
        "\n",
        "def on_condition_change(change):\n",
        "    global selected_condition # Ensure this modifies the global selected_condition\n",
        "    selected_condition = change['new']\n",
        "    n_pos = int(df_embeddings[selected_condition].sum())\n",
        "    n_total = len(df_embeddings)\n",
        "\n",
        "    with stats_output:\n",
        "        stats_output.clear_output()\n",
        "        print(f\"  â†’ Found {n_pos} positive examples out of {n_total} total.\")\n",
        "        if n_pos < 50:\n",
        "            print(f\"  â˜… WARNING: Low positive count.\")\n",
        "\n",
        "# Bind the event listener\n",
        "condition_dropdown.observe(on_condition_change, names='value')\n",
        "\n",
        "# 2. Negative Ratio Input\n",
        "initial_neg_ratio = 3.0\n",
        "if 'neg_ratio_input' in globals():\n",
        "    initial_neg_ratio = globals()['neg_ratio_input'].value\n",
        "\n",
        "neg_ratio_input = widgets.FloatText(\n",
        "    value=initial_neg_ratio,\n",
        "    description='Neg Ratio:',\n",
        "    step=0.1\n",
        ")\n",
        "\n",
        "# 3. Train Split Input\n",
        "initial_train_split = 0.7\n",
        "if 'train_split_input' in globals():\n",
        "    initial_train_split = globals()['train_split_input'].value\n",
        "\n",
        "train_split_input = widgets.FloatText(\n",
        "    value=initial_train_split,\n",
        "    description='Train Split:',\n",
        "    step=0.05\n",
        ")\n",
        "\n",
        "# Manually trigger the initial update to display stats for the dropdown's initial value\n",
        "# and to ensure `selected_condition` is set for subsequent cells.\n",
        "on_condition_change({'new': initial_dropdown_value})\n",
        "\n",
        "print(\"Select your parameters:\")\n",
        "display(condition_dropdown, stats_output, neg_ratio_input, train_split_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8bbf4d1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# =================================================================================\n",
        "# REPLACEMENT CELL: Split by Patient ID -> Balance Train Only -> Keep Val Natural\n",
        "# =================================================================================\n",
        "\n",
        "# 1. Get Inputs\n",
        "selected_condition = condition_dropdown.value\n",
        "neg_ratio = neg_ratio_input.value\n",
        "train_split_ratio = train_split_input.value\n",
        "\n",
        "print(f\"Condition: {selected_condition}\")\n",
        "print(f\"Balancing Training Data to 1:{neg_ratio} ratio.\")\n",
        "print(f\"Keeping Validation Data with natural imbalance (using all available images).\")\n",
        "\n",
        "# 2. Split Patient IDs (Stratified)\n",
        "# We split the PATIENTS first, so no patient exists in both sets.\n",
        "patient_ids = df_embeddings['Patient ID'].unique()\n",
        "# Determine if a patient is \"positive\" if they have at least one positive image\n",
        "patient_labels = df_embeddings.groupby('Patient ID')[selected_condition].max()\n",
        "\n",
        "train_ids, val_ids = train_test_split(\n",
        "    patient_ids,\n",
        "    train_size=train_split_ratio,\n",
        "    random_state=42,\n",
        "    stratify=patient_labels\n",
        ")\n",
        "\n",
        "# 3. Create Initial DataFrames (All images for the specific patients)\n",
        "train_df_raw = df_embeddings[df_embeddings['Patient ID'].isin(train_ids)]\n",
        "val_df = df_embeddings[df_embeddings['Patient ID'].isin(val_ids)].copy()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Balance ONLY the Training Set\n",
        "# ---------------------------------------------------------\n",
        "# Isolate Positives and Negatives in Training\n",
        "train_pos = train_df_raw[train_df_raw[selected_condition] == 1]\n",
        "train_neg = train_df_raw[train_df_raw[selected_condition] == 0]\n",
        "\n",
        "# Calculate how many negatives we want for training\n",
        "n_pos_train = len(train_pos)\n",
        "n_neg_target = int(n_pos_train * neg_ratio)\n",
        "n_neg_available = len(train_neg)\n",
        "\n",
        "# Sample negatives (or take all if we don't have enough)\n",
        "if n_neg_target > n_neg_available:\n",
        "    print(f\"Note: Training set requested {n_neg_target} negatives, but only {n_neg_available} available.\")\n",
        "    n_neg_final = n_neg_available\n",
        "else:\n",
        "    n_neg_final = n_neg_target\n",
        "\n",
        "train_neg_sampled = train_neg.sample(n=n_neg_final, random_state=42)\n",
        "\n",
        "# Combine to create final Training Set\n",
        "train_df = pd.concat([train_pos, train_neg_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Prepare Output Arrays\n",
        "# ---------------------------------------------------------\n",
        "X_train = np.stack(train_df['embedding'].values)\n",
        "y_train = train_df[selected_condition].values\n",
        "\n",
        "X_val = np.stack(val_df['embedding'].values)\n",
        "y_val = val_df[selected_condition].values\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. Stats & Verification\n",
        "# ---------------------------------------------------------\n",
        "def print_set_stats(name, df, condition):\n",
        "    n_p = df[condition].sum()\n",
        "    n_n = len(df) - n_p\n",
        "    ratio = n_n / n_p if n_p > 0 else 0\n",
        "    print(f\"{name}: {len(df)} images ({int(n_p)} Pos, {int(n_n)} Neg) [Ratio 1:{ratio:.1f}]\")\n",
        "\n",
        "print(f\"\\nFinal Dataset Stats:\")\n",
        "print_set_stats(\"Train Set (Balanced)\", train_df, selected_condition)\n",
        "print_set_stats(\"Tune Set (Natural) \", val_df, selected_condition)\n",
        "\n",
        "# Leakage Check\n",
        "overlap = set(train_df['Patient ID']).intersection(set(val_df['Patient ID']))\n",
        "if len(overlap) == 0:\n",
        "    print(\"\\nâœ“ SUCCESS: No patient leakage detected.\")\n",
        "else:\n",
        "    print(f\"\\nâ˜  FAIL: Leakage detected ({len(overlap)} patients).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36efafca"
      },
      "source": [
        "## Train Logistic Regression\n",
        "\n",
        "### Subtask:\n",
        "Train a logistic regression model on the prepared training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00b49dab"
      },
      "source": [
        "**Reasoning**:\n",
        "Train a logistic regression model using the prepared training data and verify the class labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3e41a99"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Instantiate the model\n",
        "log_reg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# 2. Fit the model\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Verify classes\n",
        "print(f\"Model classes: {log_reg_model.classes_}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9c887d4"
      },
      "source": [
        "## Evaluate Logistic Regression\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained Logistic Regression model on the validation set using metrics like ROC AUC, Accuracy, and Confusion Matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8280c2a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model on the validation data using various metrics and visualization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6e60de6"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
        "\n",
        "# 1. Generate predictions (Keep your existing code)\n",
        "y_pred_proba = log_reg_model.predict_proba(X_val)[:, 1]\n",
        "y_pred_binary = log_reg_model.predict(X_val)\n",
        "\n",
        "# 2. Calculate metrics\n",
        "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "accuracy = accuracy_score(y_val, y_pred_binary)\n",
        "\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Create Interactive Plot using Plotly\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Calculate the coordinates for the curve\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add the ROC Curve line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=fpr,\n",
        "    y=tpr,\n",
        "    mode='lines',\n",
        "    name=f'ROC Curve (AUC = {roc_auc:.4f})',\n",
        "    # This 'text' argument allows us to display the threshold on hover\n",
        "    text=thresholds,\n",
        "    # This formats the hover tooltip\n",
        "    hovertemplate=(\n",
        "        '<b>Threshold:</b> %{text:.4f}<br>' +\n",
        "        '<b>Sensitivity (TPR):</b> %{y:.4f}<br>' +\n",
        "        '<b>1-Specificity (FPR):</b> %{x:.4f}<extra></extra>'\n",
        "    )\n",
        "))\n",
        "\n",
        "# Add the diagonal \"No Skill\" line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[0, 1], y=[0, 1],\n",
        "    mode='lines',\n",
        "    line=dict(color='black', dash='dash'),\n",
        "    name='Chance'\n",
        "))\n",
        "\n",
        "# Update layout for labels and sizing\n",
        "fig.update_layout(\n",
        "    title=f'ROC Curve for {selected_condition}',\n",
        "    xaxis_title='False Positive Rate (1 - Specificity)',\n",
        "    yaxis_title='True Positive Rate (Sensitivity)',\n",
        "    width=700,\n",
        "    height=600,\n",
        "    showlegend=True,\n",
        "    template=\"plotly_white\" # Clean white background\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61a86d71"
      },
      "source": [
        "## Train Neural Network\n",
        "\n",
        "### Subtask:\n",
        "Define and train a TensorFlow/Keras binary classification model using the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00df1aef"
      },
      "source": [
        "**Reasoning**:\n",
        "Define and train a TensorFlow/Keras binary classification model using the training data as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee955d73"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 1. Create TensorFlow datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(128)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(128)\n",
        "\n",
        "# 2. Define the model\n",
        "weight_decay = 0#1e-5\n",
        "\n",
        "inputs = tf.keras.Input(shape=(1152,))\n",
        "hidden = layers.Dense(512,\n",
        "                      kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                      bias_regularizer=regularizers.l2(weight_decay),\n",
        "                      activation=\"relu\")(inputs)\n",
        "hidden = layers.Dropout(0.05)(hidden)\n",
        "hidden = layers.Dense(256,\n",
        "                      kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                      bias_regularizer=regularizers.l2(weight_decay),\n",
        "                      activation=\"relu\")(hidden)\n",
        "hidden = layers.Dropout(0.1)(hidden)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(hidden)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 3. Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[tf.keras.metrics.AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# 4. Train the model\n",
        "print(model.summary())\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=30\n",
        ")\n",
        "\n",
        "# Access the history dictionary\n",
        "history_dict = history.history\n",
        "\n",
        "# Extract loss values\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, loss_values, 'bo-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss_values, 'ro-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23be8388"
      },
      "source": [
        "## Evaluate Neural Network\n",
        "\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained Neural Network on the validation set using ROC AUC, Confusion Matrix, and Loss curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37d5e61d"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
        "\n",
        "# 1. Generate predictions using the Neural Network\n",
        "# model.predict returns a (N, 1) array, so we flatten it\n",
        "y_pred_proba = model.predict(X_val, verbose=0).ravel()\n",
        "y_pred_binary = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "# 2. Calculate metrics\n",
        "roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "accuracy = accuracy_score(y_val, y_pred_binary)\n",
        "\n",
        "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"Accuracy Score: {accuracy:.4f}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Create Interactive Plot using Plotly\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Calculate the coordinates for the curve\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_pred_proba)\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add the ROC Curve line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=fpr,\n",
        "    y=tpr,\n",
        "    mode='lines',\n",
        "    name=f'ROC Curve (AUC = {roc_auc:.4f})',\n",
        "    # This 'text' argument allows us to display the threshold on hover\n",
        "    text=thresholds,\n",
        "    # This formats the hover tooltip\n",
        "    hovertemplate=(\n",
        "        '<b>Threshold:</b> %{text:.4f}<br>' +\n",
        "        '<b>Sensitivity (TPR):</b> %{y:.4f}<br>' +\n",
        "        '<b>1-Specificity (FPR):</b> %{x:.4f}<extra></extra>'\n",
        "    )\n",
        "))\n",
        "\n",
        "# Add the diagonal \"No Skill\" line\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=[0, 1], y=[0, 1],\n",
        "    mode='lines',\n",
        "    line=dict(color='black', dash='dash'),\n",
        "    name='Chance'\n",
        "))\n",
        "\n",
        "# Update layout for labels and sizing\n",
        "fig.update_layout(\n",
        "    title=f'ROC Curve for {selected_condition} (Neural Network)',\n",
        "    xaxis_title='False Positive Rate (1 - Specificity)',\n",
        "    yaxis_title='True Positive Rate (Sensitivity)',\n",
        "    width=700,\n",
        "    height=600,\n",
        "    showlegend=True,\n",
        "    template=\"plotly_white\" # Clean white background\n",
        ")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Generate Predictions\n",
        "# We run the trained Neural Network (model) on the validation features (X_val)\n",
        "print(\"Generating predictions on Validation Set...\")\n",
        "y_pred_proba = model.predict(X_val, verbose=0).ravel()\n",
        "\n",
        "# 2. Create the Metadata DataFrame\n",
        "# We clone val_df so we don't mess up the original data\n",
        "df_meta = val_df.copy().reset_index(drop=True)\n",
        "\n",
        "# 3. Add Key Columns\n",
        "# 'Actual': The Ground Truth (0 or 1)\n",
        "df_meta['Actual'] = df_meta[selected_condition].values\n",
        "\n",
        "# 'Probability': The Neural Net's output score (0.0 to 1.0)\n",
        "df_meta['Probability'] = y_pred_proba\n",
        "\n",
        "# 4. Construct Full Image Paths\n",
        "# The 'path' column in the JSONL file is just the filename (e.g., \"0000001_000.png\")\n",
        "# We need the full Google Cloud Storage path for the image loader to work.\n",
        "base_gcs_url = \"gs://healthai-us/nih-cxr-14/png/\"\n",
        "\n",
        "# Ensure we handle cases where the path might already have the prefix (rare, but safe)\n",
        "def format_path(p):\n",
        "    if p.startswith(\"gs://\"): return p\n",
        "    return base_gcs_url + p\n",
        "\n",
        "df_meta['gcs_path'] = df_meta['path'].apply(format_path)\n",
        "\n",
        "# 5. Create a UI-friendly ID\n",
        "# We use the DataFrame index as a simple numeric ID for the slider/dropdown\n",
        "df_meta['ID'] = df_meta.index\n",
        "\n",
        "# 6. Filter to clean up memory\n",
        "# We only keep what the Dashboard needs\n",
        "cols_to_keep = ['ID', 'Patient Age', 'Patient Sex', 'Actual', 'Probability', 'gcs_path']\n",
        "df_meta = df_meta[cols_to_keep]\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML, Javascript\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, confusion_matrix\n",
        "\n",
        "# ==========================================\n",
        "# 1. WIDGET DEFINITIONS\n",
        "# ==========================================\n",
        "\n",
        "# A. Header\n",
        "header_html = widgets.HTML(\n",
        "    value=f\"<h2 style='margin:0; color:#333; font-family:sans-serif;'>Analysis Dashboard: <span style='color:#007bff'>{selected_condition}</span></h2>\"\n",
        ")\n",
        "\n",
        "# B. Threshold Controls (Linked Trio)\n",
        "btn_minus = widgets.Button(description='-', layout=widgets.Layout(width='35px'))\n",
        "btn_plus = widgets.Button(description='+', layout=widgets.Layout(width='35px'))\n",
        "\n",
        "txt_thresh = widgets.BoundedFloatText(\n",
        "    value=0.50, min=0.0, max=1.0, step=0.01,\n",
        "    layout=widgets.Layout(width='60px'),\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "slider_thresh = widgets.FloatSlider(\n",
        "    value=0.50, min=0.0, max=1.0, step=0.01,\n",
        "    readout=False,\n",
        "    layout=widgets.Layout(width='200px'),\n",
        "    continuous_update=True\n",
        ")\n",
        "\n",
        "widgets.jslink((txt_thresh, 'value'), (slider_thresh, 'value'))\n",
        "\n",
        "# C. Demographics\n",
        "age_slider = widgets.IntRangeSlider(\n",
        "    value=[df_meta['Patient Age'].min(), df_meta['Patient Age'].max()],\n",
        "    min=df_meta['Patient Age'].min(),\n",
        "    max=df_meta['Patient Age'].max(),\n",
        "    step=1,\n",
        "    description='Age:',\n",
        "    continuous_update=False,\n",
        "    layout=widgets.Layout(width='300px')\n",
        ")\n",
        "\n",
        "sex_dropdown = widgets.Dropdown(\n",
        "    options=['All'] + sorted(df_meta['Patient Sex'].unique().tolist()),\n",
        "    value='All',\n",
        "    description='Sex:',\n",
        "    layout=widgets.Layout(width='120px')\n",
        ")\n",
        "\n",
        "# D. Outputs\n",
        "metrics_display = widgets.HTML(value=\"Initialize...\")\n",
        "id_input = widgets.BoundedIntText(\n",
        "    value=df_meta['ID'].min(), min=0, max=df_meta['ID'].max(),\n",
        "    description='ID:', layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "out_plot = widgets.Output(layout=widgets.Layout(width='45%', height='600px', display='flex', align_items='center', justify_content='center'))\n",
        "out_table = widgets.Output(layout=widgets.Layout(width='55%', height='600px', overflow='scroll', border='1px solid #eee'))\n",
        "out_image = widgets.Output(layout=widgets.Layout(width='100%', min_height='500px', border='1px solid #ddd', margin='10px 0'))\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOGIC FUNCTIONS\n",
        "# ==========================================\n",
        "from google.cloud import storage\n",
        "\n",
        "def get_image_from_gcs(gcs_path, project_id=None):\n",
        "    try:\n",
        "        path_parts = gcs_path.replace('gs://', '').split('/', 1)\n",
        "        # Create an anonymous client if no project_id is needed/provided\n",
        "        if project_id:\n",
        "            client = storage.Client(project=project_id)\n",
        "        else:\n",
        "            client = storage.Client.create_anonymous_client()\n",
        "\n",
        "        bucket = client.bucket(path_parts[0])\n",
        "        blob = bucket.blob(path_parts[1])\n",
        "        return Image.open(io.BytesIO(blob.download_as_bytes()))\n",
        "    except Exception as e:\n",
        "        print(f\"GCS Load Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def adjust_threshold(change_amt):\n",
        "    new_val = round(txt_thresh.value + change_amt, 2)\n",
        "    if 0.0 <= new_val <= 1.0:\n",
        "        txt_thresh.value = new_val\n",
        "\n",
        "btn_minus.on_click(lambda b: adjust_threshold(-0.01))\n",
        "btn_plus.on_click(lambda b: adjust_threshold(0.01))\n",
        "\n",
        "def get_filtered_data():\n",
        "    min_age, max_age = age_slider.value\n",
        "    sex = sex_dropdown.value\n",
        "    mask = (df_meta['Patient Age'] >= min_age) & (df_meta['Patient Age'] <= max_age)\n",
        "    if sex != 'All':\n",
        "        mask = mask & (df_meta['Patient Sex'] == sex)\n",
        "    return df_meta[mask].copy().sort_values('Probability', ascending=False)\n",
        "\n",
        "def update_dashboard(change=None):\n",
        "    t = txt_thresh.value\n",
        "    df_subset = get_filtered_data()\n",
        "\n",
        "    if len(df_subset) == 0:\n",
        "        metrics_display.value = \"<b style='color:red'>No data matches filters.</b>\"\n",
        "        with out_plot: clear_output(); print(\"No Data\")\n",
        "        with out_table: clear_output(); print(\"No Data\")\n",
        "        return\n",
        "\n",
        "    # Metrics\n",
        "    preds = (df_subset['Probability'] >= t).astype(int)\n",
        "    try:\n",
        "        tn, fp, fn, tp = confusion_matrix(df_subset['Actual'], preds, labels=[0,1]).ravel()\n",
        "        sens = tp/(tp+fn) if (tp+fn)>0 else 0\n",
        "        spec = tn/(tn+fp) if (tn+fp)>0 else 0\n",
        "    except:\n",
        "        sens, spec = 0, 0\n",
        "\n",
        "    metrics_display.value = f\"\"\"\n",
        "    <div style=\"font-family: sans-serif; padding: 12px; background: #f8f9fa; border: 1px solid #e9ecef; border-radius: 5px; display: flex; gap: 30px; align-items: center; margin-bottom: 10px;\">\n",
        "        <span style=\"font-size:14px\"><b>Count:</b> {len(df_subset)}</span>\n",
        "        <span style=\"font-size:14px\"><b>Threshold:</b> {t:.2f}</span>\n",
        "        <span style=\"font-size:14px; color: #28a745;\"><b>Sensitivity:</b> {sens:.3f}</span>\n",
        "        <span style=\"font-size:14px; color: #007bff;\"><b>Specificity:</b> {spec:.3f}</span>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "    # Update Plot\n",
        "    fpr, tpr, _ = roc_curve(df_subset['Actual'], df_subset['Probability']) if len(df_subset['Actual'].unique()) > 1 else ([0,1], [0,1], 0)\n",
        "    auc_score = np.trapezoid(tpr, fpr)\n",
        "\n",
        "    with out_plot:\n",
        "        clear_output(wait=True)\n",
        "        fig, ax = plt.subplots(figsize=(9, 7))\n",
        "        ax.plot(fpr, tpr, color='#007bff', lw=3, label=f'AUC={auc_score:.2f}')\n",
        "        ax.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "        ax.plot(1-spec, sens, marker='o', color='red', markersize=14, markeredgecolor='black', zorder=10)\n",
        "        ax.set_title(f'ROC Curve: {selected_condition}', fontsize=14, fontweight='bold')\n",
        "        ax.set_xlabel('1 - Specificity')\n",
        "        ax.set_ylabel('Sensitivity')\n",
        "        ax.legend(loc=\"lower right\")\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # --- IMPROVED TABLE LOGIC ---\n",
        "    with out_table:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Split into Above and Below threshold\n",
        "        df_above = df_subset[df_subset['Probability'] >= t]\n",
        "        df_below = df_subset[df_subset['Probability'] < t]\n",
        "\n",
        "        # Smart Slice: Top 20 + [50 above ... 50 below] + Bottom 20\n",
        "        # This ensures we see the threshold context AND the extremes\n",
        "\n",
        "        slice_top = df_subset.head(20)\n",
        "        slice_above_thresh = df_above.tail(100)\n",
        "        slice_below_thresh = df_below.head(100)\n",
        "        slice_bottom = df_subset.tail(20)\n",
        "\n",
        "        # Concat and Drop Duplicates (in case list is small and slices overlap)\n",
        "        df_display = pd.concat([slice_top, slice_above_thresh, slice_below_thresh, slice_bottom])\n",
        "        df_display = df_display.drop_duplicates().sort_values('Probability', ascending=False)\n",
        "\n",
        "        html_rows = \"\"\n",
        "        line_drawn = False\n",
        "\n",
        "        for _, row in df_display.iterrows():\n",
        "            # DRAW THRESHOLD LINE\n",
        "            if not line_drawn and row['Probability'] < t:\n",
        "                html_rows += f'<tr id=\"thresh-line\" style=\"background:#ffcccc; border-top:3px solid red; border-bottom:3px solid red; font-weight:bold; color:#cc0000;\"><td colspan=\"7\" style=\"padding:8px;\">â¬‡ CUTOFF THRESHOLD ({t:.2f}) â¬‡</td></tr>'\n",
        "                line_drawn = True\n",
        "\n",
        "            pred = 1 if row['Probability'] >= t else 0\n",
        "            if row['Actual'] == 1 and pred == 1: cls, lbl = \"tp\", \"TP\"\n",
        "            elif row['Actual'] == 0 and pred == 0: cls, lbl = \"tn\", \"TN\"\n",
        "            elif row['Actual'] == 0 and pred == 1: cls, lbl = \"fp\", \"FP\"\n",
        "            elif row['Actual'] == 1 and pred == 0: cls, lbl = \"fn\", \"FN\"\n",
        "            else: cls, lbl = \"\", \"?\"\n",
        "\n",
        "            js_click = f\"google.colab.kernel.invokeFunction('select_case', [{row['ID']}], {{}})\"\n",
        "\n",
        "            bg_color = {\"tp\": \"#e6ffe6\", \"tn\": \"#ffffff\", \"fp\": \"#ffe6e6\", \"fn\": \"#fff5e6\"}.get(cls, \"#fff\")\n",
        "            font_color = {\"tp\": \"green\", \"tn\": \"navy\", \"fp\": \"#d9534f\", \"fn\": \"#f0ad4e\"}.get(cls, \"black\")\n",
        "            fw = \"bold\" if cls in [\"fp\", \"fn\"] else \"normal\"\n",
        "\n",
        "            html_rows += f'''\n",
        "            <tr style=\"background-color:{bg_color}; color:{font_color}; font-weight:{fw}; cursor:pointer; border-bottom:1px solid #f0f0f0;\" onclick=\"{js_click}\" onmouseover=\"this.style.backgroundColor='#ffffcc'\" onmouseout=\"this.style.backgroundColor='{bg_color}'\">\n",
        "                <td style=\"padding:6px;\">{row['ID']}</td>\n",
        "                <td style=\"padding:6px;\">{row['Probability']:.3f}</td>\n",
        "                <td style=\"padding:6px;\">{int(row['Actual'])}</td>\n",
        "                <td style=\"padding:6px;\">{pred}</td>\n",
        "                <td style=\"padding:6px;\">{lbl}</td>\n",
        "                <td style=\"padding:6px;\">{row['Patient Age']}</td>\n",
        "                <td style=\"padding:6px;\">{row['Patient Sex']}</td>\n",
        "            </tr>'''\n",
        "\n",
        "        table_html = f\"\"\"\n",
        "        <style> th {{ position: sticky; top: 0; background: white; z-index: 10; border-bottom: 2px solid #333; }} </style>\n",
        "        <table style=\"width:100%; border-collapse:collapse; font-family: 'Segoe UI', sans-serif; font-size:13px; text-align:center;\">\n",
        "            <thead>\n",
        "                <tr style=\"background:#f8f9fa;\">\n",
        "                    <th style=\"padding:8px;\">ID</th>\n",
        "                    <th style=\"padding:8px;\">Model Score</th>\n",
        "                    <th style=\"padding:8px;\">True</th>\n",
        "                    <th style=\"padding:8px;\">Pred</th>\n",
        "                    <th style=\"padding:8px;\">Type</th>\n",
        "                    <th style=\"padding:8px;\">Age</th>\n",
        "                    <th style=\"padding:8px;\">Sex</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>{html_rows}</tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "        display(HTML(table_html))\n",
        "\n",
        "        # SCROLL TO LINE\n",
        "        if line_drawn:\n",
        "            display(Javascript(\"\"\"\n",
        "            setTimeout(function() {\n",
        "                var el = document.getElementById(\"thresh-line\");\n",
        "                if(el) { el.scrollIntoView({behavior: \"auto\", block: \"center\", inline: \"nearest\"}); }\n",
        "            }, 300);\n",
        "            \"\"\"))\n",
        "\n",
        "# Load Image Logic\n",
        "def load_case_image(id_val):\n",
        "    idx = int(id_val)\n",
        "    id_input.value = idx\n",
        "    row_subset = df_meta[df_meta['ID'] == idx]\n",
        "\n",
        "    with out_image:\n",
        "        clear_output(wait=True)\n",
        "        if len(row_subset) == 0: print(\"ID not found.\"); return\n",
        "        row = row_subset.iloc[0]\n",
        "        try:\n",
        "            img = get_image_from_gcs(row['gcs_path'], project_id=None)\n",
        "            if img:\n",
        "                plt.figure(figsize=(7, 7))\n",
        "                plt.imshow(img, cmap='gray')\n",
        "                plt.axis('off')\n",
        "                curr_pred = 1 if row['Probability'] >= txt_thresh.value else 0\n",
        "                title = f\"ID: {idx} ({row['Patient Sex']}, {row['Patient Age']}y)\\nActual: {row['Actual']} | Pred: {curr_pred} (Score={row['Probability']:.3f})\"\n",
        "                plt.title(title, fontsize=16, color='#28a745' if row['Actual']==curr_pred else '#dc3545')\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"Image load returned None.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "\n",
        "output.register_callback('select_case', load_case_image)\n",
        "\n",
        "# ==========================================\n",
        "# 3. LAYOUT ASSEMBLY\n",
        "# ==========================================\n",
        "\n",
        "txt_thresh.observe(update_dashboard, names='value')\n",
        "age_slider.observe(update_dashboard, names='value')\n",
        "sex_dropdown.observe(update_dashboard, names='value')\n",
        "id_input.observe(lambda c: load_case_image(c['new']), names='value')\n",
        "\n",
        "controls_box = widgets.HBox([\n",
        "    widgets.VBox([\n",
        "        widgets.Label(\"Threshold:\", style={'font_weight': 'bold'}),\n",
        "        widgets.HBox([btn_minus, txt_thresh, btn_plus, slider_thresh])\n",
        "    ]),\n",
        "    widgets.HTML(\"&nbsp;&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;&nbsp;\"),\n",
        "    widgets.VBox([\n",
        "        widgets.Label(\"Demographics:\", style={'font_weight': 'bold'}),\n",
        "        widgets.HBox([age_slider, sex_dropdown])\n",
        "    ])\n",
        "], layout=widgets.Layout(align_items='center', margin='10px 0'))\n",
        "\n",
        "header_box = widgets.HBox([header_html], layout=widgets.Layout(border_bottom='2px solid #ddd', padding='10px 0'))\n",
        "\n",
        "ui_final = widgets.VBox([\n",
        "    header_box,\n",
        "    controls_box,\n",
        "    metrics_display,\n",
        "    widgets.HBox([out_plot, out_table], layout=widgets.Layout(width='100%', justify_content='space-between')),\n",
        "    widgets.HTML(\"<hr><h4 style='color:#555;'>Selected Case Viewer</h4>\"),\n",
        "    widgets.HBox([widgets.Label(\"Selected ID:\"), id_input]),\n",
        "    out_image\n",
        "])\n",
        "\n",
        "update_dashboard()\n",
        "display(ui_final)"
      ],
      "metadata": {
        "id": "QjBq-B2LmUfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot Text Embeddings"
      ],
      "metadata": {
        "id": "bXtam3MeFtKC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9ITcQtdal7J"
      },
      "source": [
        "## Get access to MedSigLIP\n",
        "\n",
        "Before you get started, make sure that you have access to MedGemma models on Hugging Face:\n",
        "\n",
        "1. If you don't already have a Hugging Face account, you can create one for free by clicking [here](https://huggingface.co/join).\n",
        "2. Head over to the [MedSiglip model page](https://huggingface.co/google/medsiglip-448) and accept the usage conditions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRFQnPL2a9Dj"
      },
      "source": [
        "### Authenticate with Hugging Face\n",
        "\n",
        "Generate a Hugging Face `read` access token by going to [settings](https://huggingface.co/settings/tokens).\n",
        "\n",
        "If you are using Google Colab, add your access token to the Colab Secrets manager to securely store it. If not, proceed to run the cell below to authenticate with Hugging Face.\n",
        "\n",
        "1. Open your Google Colab notebook and click on the ðŸ”‘ Secrets tab in the left panel. <img src=\"https://storage.googleapis.com/generativeai-downloads/images/secrets.jpg\" alt=\"The Secrets tab is found on the left panel.\" width=50%>\n",
        "2. Create a new secret with the name `HF_TOKEN`.\n",
        "3. Copy/paste your token key into the Value input box of `HF_TOKEN`.\n",
        "4. Toggle the button on the left to allow notebook access to the secret."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from transformers import AutoProcessor, AutoModel\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# ==========================================\n",
        "# 1. SETUP MODEL\n",
        "# ==========================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Loading MedSigLIP text encoder on {device}...\")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"google/medsiglip-448\")\n",
        "model = AutoModel.from_pretrained(\"google/medsiglip-448\").to(device)\n",
        "\n",
        "# ==========================================\n",
        "# 2. MULTI-PROMPT DICTIONARY\n",
        "# ==========================================\n",
        "# We use multiple variations to create a robust \"Ensemble\" embedding\n",
        "prompt_ensemble = {\n",
        "    'Pneumothorax': {\n",
        "        'pos': ['pneumothorax', 'large pneumothorax', 'small pneumothorax', 'collapsed lung', 'air in the pleural space', 'visible visceral pleural edge'],\n",
        "        'neg': ['no pneumothorax', 'normal lung', 'clear lungs', 'no evidence of pneumothorax', 'lung fields are clear']\n",
        "    },\n",
        "    'Effusion': {\n",
        "        'pos': ['pleural effusion', 'fluid in the pleural space', 'blunting of the costophrenic angle', 'meniscus sign', 'large pleural effusion'],\n",
        "        'neg': ['no pleural effusion', 'costophrenic angles are sharp', 'normal chest x-ray', 'no fluid overload']\n",
        "    },\n",
        "    'Infiltration': {\n",
        "        'pos': ['infiltration', 'pulmonary infiltrate', 'airspace opacity', 'patchy opacities', 'consolidation or infiltration'],\n",
        "        'neg': ['no infiltration', 'lungs are clear', 'no airspace opacity', 'normal lung parenchyma']\n",
        "    },\n",
        "    'Edema': {\n",
        "        'pos': ['pulmonary edema', 'interstitial edema', 'vascular congestion', 'curly b lines', 'fluid overload', 'prominent pulmonary vasculature'],\n",
        "        'neg': ['no pulmonary edema', 'no vascular congestion', 'normal pulmonary vasculature', 'dry lungs']\n",
        "    },\n",
        "    'Atelectasis': {\n",
        "        'pos': ['atelectasis', 'lung collapse', 'loss of volume', 'linear opacity', 'plate-like atelectasis'],\n",
        "        'neg': ['no atelectasis', 'fully expanded lungs', 'normal lung volumes']\n",
        "    },\n",
        "    'Nodule': {\n",
        "        'pos': ['pulmonary nodule', 'lung nodule', 'solitary pulmonary nodule', 'round opacity', 'mass or nodule'],\n",
        "        'neg': ['no nodule', 'no masses', 'clear lungs', 'normal chest']\n",
        "    },\n",
        "    'Mass': {\n",
        "        'pos': ['lung mass', 'large mass', 'tumor', 'malignancy', 'large opacity'],\n",
        "        'neg': ['no mass', 'no tumor', 'benign chest x-ray']\n",
        "    }\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 3. HELPER: AVERAGE TEXT EMBEDDING\n",
        "# ==========================================\n",
        "\n",
        "def get_averaged_text_embedding(text_list):\n",
        "    \"\"\"\n",
        "    Takes a list of strings, generates embeddings for all of them,\n",
        "    averages them, and returns a single normalized vector (1152,).\n",
        "    \"\"\"\n",
        "    # Tokenize all prompts at once\n",
        "    inputs = processor(text=text_list, images=None, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get raw features (Shape: [Batch_Size, 1152])\n",
        "        outputs = model.get_text_features(**inputs)\n",
        "\n",
        "        # 1. Normalize individual vectors first (Standard CLIP practice)\n",
        "        outputs = outputs / outputs.norm(p=2, dim=-1, keepdim=True)\n",
        "\n",
        "        # 2. Average them into one vector (Mean Pooling)\n",
        "        # Shape: [1, 1152]\n",
        "        avg_output = torch.mean(outputs, dim=0)\n",
        "\n",
        "        # 3. Normalize the final averaged vector\n",
        "        avg_output = avg_output / avg_output.norm(p=2, dim=-1, keepdim=True)\n",
        "\n",
        "    return avg_output.cpu().numpy()\n",
        "\n",
        "def compute_zero_shot_score(image_emb, pos_emb, neg_emb):\n",
        "    # Normalize Image\n",
        "    img_norm = image_emb / (np.linalg.norm(image_emb) + 1e-8)\n",
        "    # Cosine Sim\n",
        "    pos_sim = np.dot(img_norm, pos_emb)\n",
        "    neg_sim = np.dot(img_norm, neg_emb)\n",
        "    return pos_sim - neg_sim\n",
        "\n",
        "# ==========================================\n",
        "# 4. EXECUTION\n",
        "# ==========================================\n",
        "\n",
        "target_condition = selected_condition\n",
        "print(f\"\\n--- Running Ensemble Zero-Shot for: {target_condition} ---\")\n",
        "\n",
        "# Get prompts (Fallback to generic if not in dictionary)\n",
        "if target_condition in prompt_ensemble:\n",
        "    pos_list = prompt_ensemble[target_condition]['pos']\n",
        "    neg_list = prompt_ensemble[target_condition]['neg']\n",
        "    print(f\"âœ… Using Ensemble Prompts ({len(pos_list)} Pos, {len(neg_list)} Neg)\")\n",
        "else:\n",
        "    print(f\"âš ï¸ Condition not in ensemble map. Using generic prompts.\")\n",
        "    pos_list = [f\"{target_condition}\", f\"finding of {target_condition}\"]\n",
        "    neg_list = [f\"no {target_condition}\", f\"no evidence of {target_condition}\"]\n",
        "\n",
        "# Generate Ensembled Embeddings\n",
        "pos_text_emb = get_averaged_text_embedding(pos_list)\n",
        "neg_text_emb = get_averaged_text_embedding(neg_list)\n",
        "\n",
        "# Compute Scores\n",
        "zs_scores = []\n",
        "print(f\"Computing scores for {len(val_df)} validation images...\")\n",
        "\n",
        "for idx, row in val_df.iterrows():\n",
        "    img_emb = np.array(row['embedding'])\n",
        "    score = compute_zero_shot_score(img_emb, pos_text_emb, neg_text_emb)\n",
        "    zs_scores.append(score)\n",
        "\n",
        "# ==========================================\n",
        "# 5. PLOTTING\n",
        "# ==========================================\n",
        "\n",
        "y_true = val_df[target_condition].values\n",
        "y_scores = np.array(zs_scores)\n",
        "roc_auc = roc_auc_score(y_true, y_scores)\n",
        "print(f\"\\n>> Ensemble Zero-Shot AUC: {roc_auc:.4f}\")\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=fpr, y=tpr, mode='lines',\n",
        "    name=f'Ensemble ZS (AUC={roc_auc:.4f})',\n",
        "    line=dict(width=3, color='#8e44ad'), # Purple for Ensemble\n",
        "    text=thresholds,\n",
        "    hovertemplate='<b>Thresh:</b> %{text:.4f}<br><b>Sens:</b> %{y:.4f}<br><b>1-Spec:</b> %{x:.4f}<extra></extra>'\n",
        "))\n",
        "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(color='black', dash='dash'), name='Chance'))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=f'Ensemble Zero-Shot ROC: {target_condition}',\n",
        "    xaxis_title='False Positive Rate',\n",
        "    yaxis_title='True Positive Rate',\n",
        "    width=700, height=600, template=\"plotly_white\",\n",
        "    legend=dict(yanchor=\"bottom\", y=0.02, xanchor=\"right\", x=0.98, bgcolor=\"rgba(255,255,255,0.9)\", bordercolor=\"lightgrey\")\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aWG95c0oH6rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore with MedGemma"
      ],
      "metadata": {
        "id": "uQpwwfoKXfaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get access to MedGemma\n",
        "\n",
        "Before you get started, make sure that you have access to MedGemma models on Hugging Face:\n",
        "\n",
        "1. If you don't already have a Hugging Face account, you can create one for free by clicking [here](https://huggingface.co/join).\n",
        "2. Head over to the [MedGemma model page](https://huggingface.co/google/medgemma-4b-it) and accept the usage conditions."
      ],
      "metadata": {
        "id": "4cW6rdxgq8eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import pipeline, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURE & LOAD MEDGEMMA\n",
        "# ==========================================\n",
        "model_id = \"google/medgemma-4b-it\"\n",
        "use_quantization = False  # @param {type: \"boolean\"}\n",
        "model_kwargs = dict(\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "if use_quantization:\n",
        "  print(f\"Loading {model_id} with 4-bit quantization...\")\n",
        "  bnb_config = BitsAndBytesConfig(\n",
        "  load_in_4bit=True,\n",
        "  bnb_4bit_quant_type=\"nf4\",\n",
        "  bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "  model_kwargs[\"quantization_config\"] = bnb_config\n",
        "\n",
        "  # We use the pipeline API for easiest integration\n",
        "pipe = pipeline(\n",
        "    \"image-text-to-text\",\n",
        "    model=model_id,\n",
        "    model_kwargs=model_kwargs\n",
        ")\n",
        "\n",
        "print(\"MedGemma Loaded Successfully!\")\n",
        "\n",
        "# Wrapper function for cleaner usage\n",
        "def run_medgemma(pil_image, prompt_text):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"text\", \"text\": prompt_text},\n",
        "            {\"type\": \"image\", \"image\": pil_image}\n",
        "        ]}\n",
        "    ]\n",
        "    # Run generation\n",
        "    output = pipe(text=messages, max_new_tokens=300)\n",
        "    return output[0][\"generated_text\"][-1][\"content\"]"
      ],
      "metadata": {
        "id": "cr6SctL4XiHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore how MedGemma matches the MedSigLIP model"
      ],
      "metadata": {
        "id": "NngK8yAJrC8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML, Javascript, Markdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==========================================\n",
        "# 1. WIDGET DEFINITIONS\n",
        "# ==========================================\n",
        "\n",
        "# A. Header\n",
        "header_html = widgets.HTML(\n",
        "    value=f\"<h2 style='margin:0; color:#2c3e50; font-family:sans-serif;'>AI Radiologist Assistant: <span style='color:#e67e22'>MedGemma 4B</span></h2>\"\n",
        ")\n",
        "\n",
        "# B. Demographics\n",
        "age_slider = widgets.IntRangeSlider(\n",
        "    value=[df_meta['Patient Age'].min(), df_meta['Patient Age'].max()],\n",
        "    min=df_meta['Patient Age'].min(),\n",
        "    max=df_meta['Patient Age'].max(),\n",
        "    step=1,\n",
        "    description='Age:',\n",
        "    continuous_update=False,\n",
        "    layout=widgets.Layout(width='350px')\n",
        ")\n",
        "\n",
        "sex_dropdown = widgets.Dropdown(\n",
        "    options=['All'] + sorted(df_meta['Patient Sex'].unique().tolist()),\n",
        "    value='All',\n",
        "    description='Sex:',\n",
        "    layout=widgets.Layout(width='150px')\n",
        ")\n",
        "\n",
        "# C. MedGemma Controls\n",
        "default_prompt_text = f\"Describe this chest X-ray. Is there evidence of {selected_condition}? Explain your reasoning. Start by answering yes or no.\"\n",
        "\n",
        "txt_prompt = widgets.Textarea(\n",
        "    value=default_prompt_text,\n",
        "    placeholder='Enter instructions for the AI...',\n",
        "    layout=widgets.Layout(width='98%', height='100px')\n",
        ")\n",
        "\n",
        "btn_generate = widgets.Button(\n",
        "    description=\"Generate Report\",\n",
        "    button_style='success',\n",
        "    icon='magic',\n",
        "    layout=widgets.Layout(width='98%', height='40px')\n",
        ")\n",
        "\n",
        "# D. Outputs\n",
        "out_table = widgets.Output(layout=widgets.Layout(width='100%', height='350px', overflow='scroll', border='1px solid #eee', margin='0 0 20px 0'))\n",
        "id_input = widgets.BoundedIntText(value=df_meta['ID'].min(), min=0, max=df_meta['ID'].max(), description='ID:')\n",
        "out_image = widgets.Output(layout=widgets.Layout(width='50%', min_height='500px', border='1px solid #ddd'))\n",
        "out_report = widgets.Output(layout=widgets.Layout(width='50%', min_height='500px', border='1px solid #ddd', padding='15px', overflow='auto'))\n",
        "\n",
        "current_img_cache = None\n",
        "\n",
        "# ==========================================\n",
        "# 2. LOGIC FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "def get_filtered_data():\n",
        "    min_age, max_age = age_slider.value\n",
        "    sex = sex_dropdown.value\n",
        "    mask = (df_meta['Patient Age'] >= min_age) & (df_meta['Patient Age'] <= max_age)\n",
        "    if sex != 'All':\n",
        "        mask = mask & (df_meta['Patient Sex'] == sex)\n",
        "\n",
        "    # Sort: Put Positives (Actual=1) at the top, then high probabilities\n",
        "    return df_meta[mask].copy().sort_values(['Actual', 'Probability'], ascending=[False, False])\n",
        "\n",
        "def update_table(change=None):\n",
        "    df_subset = get_filtered_data()\n",
        "\n",
        "    with out_table:\n",
        "        clear_output(wait=True)\n",
        "        if len(df_subset) == 0:\n",
        "            print(\"No data found.\")\n",
        "            return\n",
        "\n",
        "        html_rows = \"\"\n",
        "        # Limit to 200 rows for the selector table\n",
        "        for _, row in df_subset.head(200).iterrows():\n",
        "\n",
        "            # Styling based on Ground Truth\n",
        "            is_pos = (row['Actual'] == 1)\n",
        "            bg_color = \"#fff0f0\" if is_pos else \"#f0fff0\"\n",
        "            status_color = \"#cc0000\" if is_pos else \"green\"\n",
        "            status_text = \"POSITIVE\" if is_pos else \"Negative\"\n",
        "            fw = \"bold\" if is_pos else \"normal\"\n",
        "\n",
        "            # Styling for Score\n",
        "            score = row['Probability']\n",
        "            score_color = \"black\"\n",
        "            if score > 0.7: score_color = \"red\"\n",
        "            elif score < 0.3: score_color = \"blue\"\n",
        "\n",
        "            js_click = f\"google.colab.kernel.invokeFunction('select_case_gemma', [{row['ID']}], {{}})\"\n",
        "\n",
        "            html_rows += f'''\n",
        "            <tr style=\"background-color:{bg_color}; cursor:pointer; border-bottom:1px solid #e0e0e0;\" onclick=\"{js_click}\" onmouseover=\"this.style.backgroundColor='#ffffcc'\" onmouseout=\"this.style.backgroundColor='{bg_color}'\">\n",
        "                <td style=\"padding:8px;\">{row['ID']}</td>\n",
        "                <td style=\"padding:8px; font-weight:bold; color:{score_color};\">{score:.3f}</td>\n",
        "                <td style=\"padding:8px; color:{status_color}; font-weight:{fw};\">{status_text}</td>\n",
        "                <td style=\"padding:8px;\">{row['Patient Age']}</td>\n",
        "                <td style=\"padding:8px;\">{row['Patient Sex']}</td>\n",
        "                <td style=\"padding:8px; color:#999;\">Click to Load âž¡</td>\n",
        "            </tr>'''\n",
        "\n",
        "        table_html = f\"\"\"\n",
        "        <style> th {{ position: sticky; top: 0; background: white; z-index: 10; border-bottom: 2px solid #333; }} </style>\n",
        "        <table style=\"width:100%; border-collapse:collapse; font-family: 'Segoe UI', sans-serif; font-size:13px; text-align:center;\">\n",
        "            <thead>\n",
        "                <tr style=\"background:#f8f9fa;\">\n",
        "                    <th style=\"padding:10px;\">ID</th>\n",
        "                    <th style=\"padding:10px;\">Model Score</th>\n",
        "                    <th style=\"padding:10px;\">Ground Truth</th>\n",
        "                    <th style=\"padding:10px;\">Age</th>\n",
        "                    <th style=\"padding:10px;\">Sex</th>\n",
        "                    <th style=\"padding:10px;\">Action</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>{html_rows}</tbody>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "        display(HTML(table_html))\n",
        "\n",
        "def load_case_image(id_val):\n",
        "    global current_img_cache\n",
        "    idx = int(id_val)\n",
        "    id_input.value = idx\n",
        "    row_subset = df_meta[df_meta['ID'] == idx]\n",
        "\n",
        "    with out_report: clear_output(); print(\"Waiting for analysis...\")\n",
        "\n",
        "    with out_image:\n",
        "        clear_output(wait=True)\n",
        "        if len(row_subset) == 0: print(\"ID not found.\"); return\n",
        "        row = row_subset.iloc[0]\n",
        "        try:\n",
        "            img = get_image_from_gcs(row['gcs_path'], project_id=None)\n",
        "            if img:\n",
        "                current_img_cache = img\n",
        "                plt.figure(figsize=(7, 7))\n",
        "                plt.imshow(img, cmap='gray')\n",
        "                plt.axis('off')\n",
        "\n",
        "                status_text = \"POS\" if row['Actual'] == 1 else \"NEG\"\n",
        "                color = \"#d63031\" if row['Actual'] == 1 else \"#00b894\"\n",
        "                title_str = f\"ID: {idx}  |  Score: {row['Probability']:.3f}  |  Truth: {status_text}\"\n",
        "\n",
        "                plt.title(title_str, color=color, fontsize=15, fontweight='bold', pad=10)\n",
        "                plt.show()\n",
        "            else:\n",
        "                print(\"Image load returned None.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "\n",
        "def run_inference(b):\n",
        "    if current_img_cache is None:\n",
        "        with out_report: print(\"Please select an image from the table first.\")\n",
        "        return\n",
        "\n",
        "    with out_report:\n",
        "        clear_output()\n",
        "        display(HTML(\"<b>MedGemma is analyzing...</b> <span style='color:gray'>(approx 10-20s)</span>\"))\n",
        "        display(widgets.IntProgress(value=0, min=0, max=10, layout=widgets.Layout(width='200px')))\n",
        "\n",
        "        try:\n",
        "            messages = [\n",
        "                {\"role\": \"user\", \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": txt_prompt.value},\n",
        "                    {\"type\": \"image\", \"image\": current_img_cache}\n",
        "                ]}\n",
        "            ]\n",
        "            output = pipe(text=messages, max_new_tokens=500)\n",
        "            response = output[0][\"generated_text\"][-1][\"content\"]\n",
        "\n",
        "            clear_output()\n",
        "            display(Markdown(\"### ðŸ©º MedGemma Report\"))\n",
        "            display(Markdown(\"---\"))\n",
        "            display(Markdown(response))\n",
        "\n",
        "        except Exception as e:\n",
        "            clear_output()\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "output.register_callback('select_case_gemma', load_case_image)\n",
        "\n",
        "# ==========================================\n",
        "# 3. LAYOUT ASSEMBLY\n",
        "# ==========================================\n",
        "\n",
        "age_slider.observe(update_table, names='value')\n",
        "sex_dropdown.observe(update_table, names='value')\n",
        "id_input.observe(lambda c: load_case_image(c['new']), names='value')\n",
        "btn_generate.on_click(run_inference)\n",
        "\n",
        "controls_box = widgets.HBox([\n",
        "    widgets.HTML(\"<b>Filter Patients:</b>\"),\n",
        "    age_slider,\n",
        "    sex_dropdown\n",
        "], layout=widgets.Layout(align_items='center', margin='10px 0', padding='10px', border='1px solid #eee'))\n",
        "\n",
        "prompt_area = widgets.VBox([\n",
        "    widgets.HTML(\"<b>Radiologist Prompt:</b>\"),\n",
        "    txt_prompt,\n",
        "    btn_generate\n",
        "], layout=widgets.Layout(margin='0 0 20px 0'))\n",
        "\n",
        "workspace = widgets.HBox([\n",
        "    out_image,\n",
        "    widgets.VBox([\n",
        "        prompt_area,\n",
        "        widgets.HTML(\"<b>AI Findings:</b>\"),\n",
        "        out_report\n",
        "    ], layout=widgets.Layout(width='50%', padding='0 0 0 20px'))\n",
        "])\n",
        "\n",
        "ui_gemma = widgets.VBox([\n",
        "    widgets.HBox([header_html], layout=widgets.Layout(border_bottom='2px solid #e67e22', padding='15px 0')),\n",
        "    controls_box,\n",
        "    widgets.HTML(\"<b>Select a Case (Sorted by Condition):</b>\"),\n",
        "    out_table,\n",
        "    widgets.HTML(\"<hr>\"),\n",
        "    widgets.HBox([widgets.Label(\"Selected ID:\"), id_input]),\n",
        "    workspace\n",
        "])\n",
        "\n",
        "update_table()\n",
        "display(ui_gemma)"
      ],
      "metadata": {
        "id": "pHAkGnFIaxIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
